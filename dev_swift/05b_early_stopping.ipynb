{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/home/ubuntu/git/fastai_docs/dev_swift/FastaiNotebook_05_anneal\")\n",
      "\t\tFastaiNotebook_05_anneal\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpt4oiohwp/swift-install\n",
      "/home/ubuntu/swift/usr/bin/swift-build: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/lib/swift/linux/libFoundation.so)\n",
      "/home/ubuntu/swift/usr/bin/swift-build: /home/ubuntu/anaconda3/lib/libcurl.so.4: no version information available (required by /home/ubuntu/swift/usr/lib/swift/linux/libFoundation.so)\n",
      "/home/ubuntu/swift/usr/bin/swiftc: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swiftc)\n",
      "Compile Swift Module 'FastaiNotebook_05_anneal' (8 sources)\n",
      "/home/ubuntu/swift/usr/bin/swiftc: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/ubuntu/swift/usr/bin/swift: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swift)\n",
      "\n",
      "/home/ubuntu/swift/usr/bin/swift: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swift)\n",
      "\n",
      "/home/ubuntu/swift/usr/bin/swift: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swift)\n",
      "\n",
      "/home/ubuntu/swift/usr/bin/swift: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swift)\n",
      "\n",
      "/home/ubuntu/swift/usr/bin/swift: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swift)\n",
      "\n",
      "Compile Swift Module 'jupyterInstalledPackages' (1 sources)\n",
      "/home/ubuntu/swift/usr/bin/swiftc: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/ubuntu/swift/usr/bin/swift: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swift)\n",
      "\n",
      "/home/ubuntu/swift/usr/bin/swift: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swift)\n",
      "\n",
      "Linking ./.build/x86_64-unknown-linux/debug/libjupyterInstalledPackages.so\n",
      "/home/ubuntu/swift/usr/bin/swiftc: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/ubuntu/swift/usr/bin/swift-autolink-extract: /home/ubuntu/anaconda3/lib/libuuid.so.1: no version information available (required by /home/ubuntu/swift/usr/bin/swift-autolink-extract)\n",
      "\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/swift-install\n",
    "%install '.package(path: \"$cwd/FastaiNotebook_05_anneal\")' FastaiNotebook_05_anneal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "import Path\n",
    "import TensorFlow\n",
    "import Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FastaiNotebook_05_anneal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('inline', 'module://ipykernel.pylab.backend_inline')\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let data = mnistDataBunch(flat: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (n,m) = (60000,784)\n",
    "let c = 10\n",
    "let nHid = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func optFunc(_ model: BasicModel) -> SGD<BasicModel> {return SGD(for: model, learningRate: 1e-2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func modelInit() -> BasicModel {return BasicModel(nIn: m, nHid: nHid, nOut: c)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunc: softmaxCrossEntropy, optFunc: optFunc, modelInit: modelInit)\n",
    "let recorder = learner.makeRecorder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the previous callbacks load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.delegates = [learner.makeTrainEvalDelegate(), learner.makeShowProgress(),\n",
    "                     learner.makeNormalize(mean: mnistStats.mean, std: mnistStats.std),\n",
    "                     learner.makeAvgMetric(metrics: [accuracy]), recorder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an extension to quickly load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "//TODO: when recorder can be accessed as a property, remove it from the return\n",
    "extension Learner where Opt.Scalar: PythonConvertible {\n",
    "    public func makeDefaultDelegates(metrics: [(Tensor<Float>, Tensor<Int32>) -> Tensor<Float>] = []) -> Recorder {\n",
    "        let recorder = makeRecorder()\n",
    "        delegates = [makeTrainEvalDelegate(), makeShowProgress(), recorder]\n",
    "        if !metrics.isEmpty { delegates.append(makeAvgMetric(metrics: metrics)) }\n",
    "        return recorder\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Flow test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Learner {\n",
    "    public class TestControlFlow: Delegate {\n",
    "        public override var order: Int { return 3 }\n",
    "        var waitForSkipBatch, waitForSkipEpoch, waitForEndTrain: Int\n",
    "        \n",
    "        public init(nIter:Int, nBatch: Int, nEpoch: Int){ \n",
    "            (waitForSkipBatch, waitForSkipEpoch, waitForEndTrain) = (nIter, nBatch, nEpoch)\n",
    "        }\n",
    "        \n",
    "        public override func didProduceNewGradient(learner: Learner) throws {\n",
    "            if learner.currentIter >= waitForSkipBatch {throw LearnerAction.skipBatch}\n",
    "        }\n",
    "        \n",
    "        public override func batchDidFinish(learner: Learner) throws {\n",
    "            if learner.currentIter >= waitForSkipBatch {\n",
    "                print(\"batchDidFinish properly executed after skip batch at iter \\(learner.currentIter)\")\n",
    "            }\n",
    "            if learner.currentIter >= waitForSkipEpoch {throw LearnerAction.skipEpoch}\n",
    "            }\n",
    "        \n",
    "        public override func epochDidFinish(learner: Learner) throws {\n",
    "            print(\"epochDidFinish properly executed after skip epoch (number \\(learner.currentEpoch))\")\n",
    "            if learner.currentEpoch >= waitForEndTrain {throw LearnerAction.stop}\n",
    "        }\n",
    "        \n",
    "        public override func trainingDidFinish(learner: Learner){\n",
    "            print(\"trainingDidFinish properly executed after stop\")\n",
    "        }     \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunc: softmaxCrossEntropy, optFunc: optFunc, modelInit: modelInit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.delegates = [type(of: learner).TestControlFlow(nIter:5, nBatch: 7, nEpoch: 2),\n",
    "                     learner.makeTrainEvalDelegate()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the orders were taken into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(learner.delegates[0].order,learner.delegates[1].order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "extension Learner where Opt.Scalar: BinaryFloatingPoint {\n",
    "    public class LRFinder: Delegate {\n",
    "        public typealias ScheduleFunc = (Float) -> Float\n",
    "\n",
    "        // A learning rate schedule from step to float.\n",
    "        private var scheduler: ScheduleFunc\n",
    "        private var numIter: Int\n",
    "        private var minLoss: Float? = nil\n",
    "        \n",
    "        public init(start: Float = 1e-5, end: Float = 10, numIter: Int = 100) {\n",
    "            scheduler = makeAnnealer(start: start, end: end, schedule: expSchedule)\n",
    "            self.numIter = numIter\n",
    "        }\n",
    "        \n",
    "        override public func batchWillStart(learner: Learner) {\n",
    "            learner.opt.learningRate = Opt.Scalar(scheduler(Float(learner.currentIter)/Float(numIter)))\n",
    "        }\n",
    "        \n",
    "        override public func batchDidFinish(learner: Learner) throws {\n",
    "            if minLoss == nil {minLoss = learner.currentLoss.scalar}\n",
    "            else { \n",
    "                if learner.currentLoss.scalarized() < minLoss! { minLoss = learner.currentLoss.scalarized()}\n",
    "                if learner.currentLoss.scalarized() > 4 * minLoss! { throw LearnerAction.stop }\n",
    "                if learner.currentIter >= numIter { throw LearnerAction.stop }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        override public func validationWillStart(learner: Learner<Label, Opt>) throws {\n",
    "            //Skip validation during the LR range test\n",
    "            throw LearnerAction.skipEpoch\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    public func makeLRFinder(start: Float = 1e-5, end: Float = 10, numIter: Int = 100) -> LRFinder {\n",
    "        return LRFinder(start: start, end: end, numIter: numIter)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunc: softmaxCrossEntropy, optFunc: optFunc, modelInit: modelInit)\n",
    "let recorder = learner.makeDefaultDelegates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.delegates.append(learner.makeNormalize(mean: mnistStats.mean, std: mnistStats.std))\n",
    "learner.delegates.append(learner.makeLRFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.plotLRFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "//TODO: when Recorder is a property of Learner don't return it.\n",
    "extension Learner where Opt.Scalar: PythonConvertible & BinaryFloatingPoint {\n",
    "    public func lrFind(start: Float = 1e-5, end: Float = 10, numIter: Int = 100) -> Recorder {\n",
    "        let epochCount = data.train.count/numIter + 1\n",
    "        let recorder = makeDefaultDelegates()\n",
    "        delegates.append(makeLRFinder(start: start, end: end, numIter: numIter))\n",
    "        try! self.fit(epochCount)\n",
    "        return recorder\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let recorder = learner.lrFind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.plotLRFinder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebookToScript(fname: Path.cwd / \"05b_early_stopping.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
