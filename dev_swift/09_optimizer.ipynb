{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/home/ubuntu/fastai_docs/dev_swift/FastaiNotebook_04_callbacks\")\n",
      "\t\tFastaiNotebook_04_callbacks\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmptubdev2g\n",
      "Fetching https://github.com/mxcl/Path.swift\n",
      "Fetching https://github.com/JustHTTP/Just\n",
      "Completed resolution in 3.56s\n",
      "Cloning https://github.com/JustHTTP/Just\n",
      "Resolving https://github.com/JustHTTP/Just at 0.7.1\n",
      "Cloning https://github.com/mxcl/Path.swift\n",
      "Resolving https://github.com/mxcl/Path.swift at 0.16.2\n",
      "Compile Swift Module 'Path' (9 sources)\n",
      "Compile Swift Module 'Just' (1 sources)\n",
      "Compile Swift Module 'FastaiNotebook_04_callbacks' (6 sources)\n",
      "Compile Swift Module 'jupyterInstalledPackages' (1 sources)\n",
      "Linking ./.build/x86_64-unknown-linux/debug/libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Loading library...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install '.package(path: \"$cwd/FastaiNotebook_04_callbacks\")' FastaiNotebook_04_callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('inline', 'module://ipykernel.pylab.backend_inline')\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import FastaiNotebook_04_callbacks\n",
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "import Path\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let data = mnistDataBunch(flat: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (n,m) = (60000,784)\n",
    "let c = 10\n",
    "let nHid = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func modelInit() -> BasicModel {return BasicModel(nIn: m, nHid: nHid, nOut: c)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: When TF-421 is fixed, switch back to the normal `softmaxCrossEntropy`.\n",
    "\n",
    "@differentiable(vjp: _vjpSoftmaxCrossEntropy)\n",
    "func softmaxCrossEntropy1<Scalar: TensorFlowFloatingPoint>(\n",
    "    _ features: Tensor<Scalar>, _ labels: Tensor<Scalar>\n",
    ") -> Tensor<Scalar> {\n",
    "    return Raw.softmaxCrossEntropyWithLogits(features: features, labels: labels).loss.mean()\n",
    "}\n",
    "\n",
    "@usableFromInline\n",
    "func _vjpSoftmaxCrossEntropy<Scalar: TensorFlowFloatingPoint>(\n",
    "    features: Tensor<Scalar>, labels: Tensor<Scalar>\n",
    ") -> (Tensor<Scalar>, (Tensor<Scalar>) -> (Tensor<Scalar>, Tensor<Scalar>)) {\n",
    "    let (loss, grad) = Raw.softmaxCrossEntropyWithLogits(features: features, labels: labels)\n",
    "    let batchSize = Tensor<Scalar>(features.shapeTensor[0])\n",
    "    return (loss.mean(), { v in ((v / batchSize) * grad, Tensor<Scalar>(0)) })\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "open class StatDelegate<Scalar: TensorFlowFloatingPoint> {\n",
    "    open var name: String { return \"\" }\n",
    "    var defaultConfig: [String: Scalar] { return [:] }\n",
    "    func update(\n",
    "        state: inout [String: Tensor<Scalar>],\n",
    "        for param: Tensor<Scalar>,\n",
    "        along direction: Tensor<Scalar>,\n",
    "        config: inout [String: Scalar]\n",
    "    ) { }\n",
    "}\n",
    "\n",
    "//export\n",
    "open class StepDelegate<Scalar: TensorFlowFloatingPoint> {\n",
    "    var defaultConfig: [String: Scalar] { return [:] }\n",
    "    func update(\n",
    "        param: inout Tensor<Scalar>,\n",
    "        along direction: inout Tensor<Scalar>,\n",
    "        state: [String: Tensor<Scalar>],\n",
    "        config: inout [String: Scalar]\n",
    "    ) { }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class StatefulOptimizer<Model: Layer,\n",
    "                        Scalar: TensorFlowFloatingPoint>: Optimizer\n",
    "    where Model.AllDifferentiableVariables == Model.CotangentVector{\n",
    "    var config: [String: Scalar]\n",
    "    var learningRate: Scalar {\n",
    "        get { return config[\"learningRate\"]!} \n",
    "        set { config[\"learningRate\"] = newValue }\n",
    "    }\n",
    "    var states: [String: Model.AllDifferentiableVariables]\n",
    "    var statDelegates: [StatDelegate<Scalar>]\n",
    "    var stepDelegates: [StepDelegate<Scalar>]\n",
    "    init(\n",
    "        stepDelegates: [StepDelegate<Scalar>],\n",
    "        statDelegates: [StatDelegate<Scalar>],\n",
    "        config: [String: Scalar]\n",
    "    ) {\n",
    "        self.config = [:]\n",
    "        states = [:]\n",
    "        for stepDelegate in stepDelegates {\n",
    "            self.config.merge(stepDelegate.defaultConfig) { (_, new) in new }\n",
    "        }\n",
    "        for statDelegate in statDelegates {\n",
    "            self.config.merge(statDelegate.defaultConfig) { (_, new) in new }\n",
    "            states[statDelegate.name] = Model.AllDifferentiableVariables.zero\n",
    "        }\n",
    "        self.config.merge(config) { (_, new) in new }\n",
    "        self.stepDelegates = stepDelegates\n",
    "        self.statDelegates = statDelegates\n",
    "    }\n",
    "    func update(\n",
    "        _ model: inout Model.AllDifferentiableVariables,\n",
    "        along direction: Model.CotangentVector\n",
    "    ) {\n",
    "        for kp in model.recursivelyAllWritableKeyPaths(to: Tensor<Scalar>.self) {\n",
    "            var grad = direction[keyPath: kp]\n",
    "            var state = states.mapValues(){$0[keyPath: kp]}\n",
    "            for statDelegate in statDelegates {\n",
    "                statDelegate.update(\n",
    "                    state: &state,\n",
    "                    for: model[keyPath: kp],\n",
    "                    along: grad,\n",
    "                    config: &config\n",
    "                )\n",
    "            }\n",
    "            for n in states.keys { states[n]![keyPath: kp] = state[n]! }\n",
    "            for stepDelegate in stepDelegates {\n",
    "                stepDelegate.update(\n",
    "                    param: &model[keyPath: kp],\n",
    "                    along: &grad,\n",
    "                    state: state,\n",
    "                    config: &config\n",
    "                )\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class SGDStep<Scalar: TensorFlowFloatingPoint>: StepDelegate<Scalar> {\n",
    "    override func update(\n",
    "        param: inout Tensor<Scalar>,\n",
    "        along direction: inout Tensor<Scalar>,\n",
    "        state: [String: Tensor<Scalar>],\n",
    "        config: inout [String: Scalar]\n",
    "    ) {\n",
    "        param -= Scalar(config[\"learningRate\"]!) * direction\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class WeightDecay<Scalar: TensorFlowFloatingPoint>: StepDelegate<Scalar> {\n",
    "    override var defaultConfig: [String: Scalar] { return [\"weightDecay\": 0.0] }\n",
    "    override func update(\n",
    "        param: inout Tensor<Scalar>,\n",
    "        along direction: inout Tensor<Scalar>,\n",
    "        state: [String: Tensor<Scalar>],\n",
    "        config: inout [String: Scalar]\n",
    "    ) {\n",
    "        param *= 1 - config[\"learningRate\"]! * config[\"weightDecay\"]!\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class L2Regularization<Scalar: TensorFlowFloatingPoint>: StepDelegate<Scalar> {\n",
    "    override var defaultConfig: [String: Scalar] { return [\"weightDecay\": 0.0] }\n",
    "    override func update(\n",
    "        param: inout Tensor<Scalar>,\n",
    "        along direction: inout Tensor<Scalar>,\n",
    "        state: [String: Tensor<Scalar>],\n",
    "        config: inout [String: Scalar]\n",
    "    ) {\n",
    "        direction += config[\"weightDecay\"]! * param\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class AverageGrad<Scalar: TensorFlowFloatingPoint>: StatDelegate<Scalar> {\n",
    "    override var defaultConfig: [String: Scalar] { return [\"momentum\": 0.9] }\n",
    "    let dampened: Bool\n",
    "    init(dampened: Bool = false) { self.dampened = dampened }\n",
    "    override var name: String { return \"averageGrad\" }\n",
    "    override func update(\n",
    "        state: inout [String: Tensor<Scalar>],\n",
    "        for param: Tensor<Scalar>,\n",
    "        along direction: Tensor<Scalar>,\n",
    "        config: inout [String: Scalar]\n",
    "    ) {\n",
    "        state[\"averageGrad\"]! *= config[\"momentum\"]!\n",
    "        config[\"momentumDampening\"] = 1.0 - (dampened ? config[\"momentum\"]! : 0.0)\n",
    "        state[\"averageGrad\"]! += config[\"momentumDampening\"]! * direction\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let opt = StatefulOptimizer<BasicModel, Float>(stepDelegates: [SGDStep()], statDelegates: [], \n",
    "                                               config: [\"learningRate\":0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunction: softmaxCrossEntropy1, optimizer: opt, initializingWith: modelInit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.delegates = [Learner.TrainEvalDelegate(), Learner.AvgMetric(metrics: [accuracy])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: [0.46199676, 0.8835]\n",
      "Epoch 1: [0.35245648, 0.9038]\n"
     ]
    }
   ],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class MomentumStep<Scalar: TensorFlowFloatingPoint>: StepDelegate<Scalar> {\n",
    "    override func update(\n",
    "        param: inout Tensor<Scalar>,\n",
    "        along direction: inout Tensor<Scalar>,\n",
    "        state: [String: Tensor<Scalar>],\n",
    "        config: inout [String: Scalar]\n",
    "    ) {\n",
    "        param -= config[\"learningRate\"]! * state[\"averageGrad\"]!\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let opt = StatefulOptimizer<BasicModel, Float>(stepDelegates: [MomentumStep()], statDelegates: [AverageGrad()], \n",
    "                                               config: [\"learningRate\":0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunction: softmaxCrossEntropy1, optimizer: opt, initializingWith: modelInit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.delegates = [Learner.TrainEvalDelegate(), Learner.AvgMetric(metrics: [accuracy])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: [0.24837255, 0.9279]\n",
      "Epoch 1: [0.17791083, 0.9486]\n"
     ]
    }
   ],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class AverageSquaredGrad<Scalar: TensorFlowFloatingPoint>: StatDelegate<Scalar> {\n",
    "    override var defaultConfig: [String: Scalar] { return [\"squareMomentum\": 0.99] }\n",
    "    let dampened: Bool\n",
    "    init(dampened: Bool = false) { self.dampened = dampened }\n",
    "    override var name: String { return \"averageSquaredGrad\" }\n",
    "    override func update(\n",
    "        state: inout [String: Tensor<Scalar>],\n",
    "        for param: Tensor<Scalar>,\n",
    "        along direction: Tensor<Scalar>,\n",
    "        config: inout [String: Scalar]\n",
    "    ) {\n",
    "        state[\"averageSquaredGrad\"]! *= config[\"squareMomentum\"]!\n",
    "        config[\"squareMomentumDampening\"] = 1.0 - (dampened ? config[\"squareMomentum\"]! : 0.0)\n",
    "        state[\"averageSquaredGrad\"]! += config[\"squareMomentumDampening\"]! * direction.squared()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class StepCount<Scalar: TensorFlowFloatingPoint>: StatDelegate<Scalar> {\n",
    "    override var name: String { return \"step\" }\n",
    "    override func update(\n",
    "        state: inout [String: Tensor<Scalar>],\n",
    "        for param: Tensor<Scalar>,\n",
    "        along direction: Tensor<Scalar>,\n",
    "        config: inout [String: Scalar]\n",
    "    ) {\n",
    "        state[\"step\"]! += 1.0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "func debias<Scalar: TensorFlowFloatingPoint>(\n",
    "    momentum: Scalar,\n",
    "    dampening: Scalar,\n",
    "    step: Tensor<Scalar> \n",
    ") -> Tensor<Scalar> {\n",
    "    return dampening * (1 - pow(momentum, step)) / (1 - momentum)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class AdamStep<Scalar: TensorFlowFloatingPoint>: StepDelegate<Scalar> {\n",
    "    override var defaultConfig: [String: Scalar] { return [\"epsilon\": 1e-5] }\n",
    "    override func update(\n",
    "        param: inout Tensor<Scalar>,\n",
    "        along direction: inout Tensor<Scalar>,\n",
    "        state: [String: Tensor<Scalar>],\n",
    "        config: inout [String: Scalar]\n",
    "    ) {\n",
    "        let debiasedLearningRate = config[\"learningRate\"]! / debias(\n",
    "            momentum: config[\"momentum\"]!,\n",
    "            dampening: config[\"momentumDampening\"]!,\n",
    "            step: state[\"step\"]!\n",
    "        )\n",
    "        let debiasedRMSGrad = sqrt(state[\"averageSquaredGrad\"]! / debias(\n",
    "            momentum: config[\"squareMomentum\"]!,\n",
    "            dampening: config[\"squareMomentumDampening\"]!,\n",
    "            step: state[\"step\"]!\n",
    "        )) + config[\"epsilon\"]!\n",
    "        param -= debiasedLearningRate * state[\"averageGrad\"]! / debiasedRMSGrad\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let opt = StatefulOptimizer<BasicModel, Float>(\n",
    "    stepDelegates: [AdamStep()], \n",
    "    statDelegates: [AverageGrad(), AverageSquaredGrad(), StepCount()], \n",
    "    config: [\"learningRate\":0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunction: softmaxCrossEntropy1, optimizer: opt, initializingWith: modelInit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.delegates = [Learner.TrainEvalDelegate(), Learner.AvgMetric(metrics: [accuracy])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: [0.18092719, 0.9477]\n",
      "Epoch 1: [0.14641517, 0.9578]\n"
     ]
    }
   ],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambStep<Scalar: TensorFlowFloatingPoint>: StepDelegate<Scalar> {\n",
    "    override var defaultConfig: [String: Scalar] {\n",
    "        return [\"epsilon\": 1e-6, \"weightDecay\": 0.0]\n",
    "    }\n",
    "    override func update(\n",
    "        param: inout Tensor<Scalar>,\n",
    "        along direction: inout Tensor<Scalar>,\n",
    "        state: [String: Tensor<Scalar>],\n",
    "        config: inout [String: Scalar]\n",
    "    ) {\n",
    "        let debiasedAverageGrad = state[\"averageGrad\"]! / debias(\n",
    "            momentum: config[\"momentum\"]!,\n",
    "            dampening: config[\"momentumDampening\"]!,\n",
    "            step: state[\"step\"]!\n",
    "        )\n",
    "        let debiasedRMSGrad = sqrt(state[\"averageSquaredGrad\"]! / debias(\n",
    "            momentum: config[\"squareMomentum\"]!,\n",
    "            dampening: config[\"squareMomentumDampening\"]!,\n",
    "            step: state[\"step\"]!\n",
    "        ) + config[\"epsilon\"]!)\n",
    "        let step = debiasedAverageGrad / debiasedRMSGrad + config[\"weightDecay\"]! * param\n",
    "        let r1 = sqrt((param * param).mean())\n",
    "        let r2 = sqrt((step * step).mean())\n",
    "        let factor = min(r1 / r2, Scalar(10.0))\n",
    "        param -= config[\"learningRate\"]! * factor * step\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebookToScript(fname: (Path.cwd / \"09_optimizer.ipynb\").string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
