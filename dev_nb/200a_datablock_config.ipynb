{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.datasets import URLs, untar_data\n",
    "from pathlib import Path\n",
    "import torch, re, PIL, os, mimetypes, csv, operator, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from typing import *\n",
    "import pandas as pd, numpy as np\n",
    "from enum import Enum\n",
    "from torch import tensor,Tensor\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data block API from config class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def noop(x, *args, **kwargs): return x\n",
    "def range_of(x): return list(range(len(x)))\n",
    "torch.Tensor.ndim = property(lambda x: x.dim())\n",
    "\n",
    "def test(a,b,cmp,cname=None,tst_name=''):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f\"{tst_name},{cname}:\\n{a}\\n{b}\"\n",
    "\n",
    "def test_eq(a,b,tst_name=''): \n",
    "    if isinstance(a, np.ndarray) or (isinstance(a, Tensor) and a.ndim):\n",
    "        assert len(a) == len(b), f\"{tst_name}, lengths mismatch:\\n{a}\\n{b}\"\n",
    "        test(a,b,lambda x,y: (x == y).all(),'==',tst_name)\n",
    "    else: test(a,b,operator.eq,'==',tst_name)\n",
    "\n",
    "def test_ne(a,b):    test(a,b,operator.ne,'!=')\n",
    "\n",
    "def compose(*funcs): return reduce(lambda f,g: lambda x: f(g(x)), reversed(funcs), noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def noop(x, *args, **kwargs): return x\n",
    "def range_of(x): return list(range(len(x)))\n",
    "torch.Tensor.ndim = property(lambda x: x.dim())\n",
    "\n",
    "def test(a,b,cmp,cname=None,tst_name='', tf=True):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b)==tf,f\"{tst_name},{cname}:\\n{a}\\n{b}\"\n",
    "\n",
    "def test_eq(a,b,tst_name='', tf=True): \n",
    "    op = (np.array_equal if isinstance(a, np.ndarray)\n",
    "          else torch.equal if isinstance(a, Tensor) and a.ndim\n",
    "          else operator.eq)\n",
    "    return test(a,b,op,'==',tst_name=tst_name, tf=tf)\n",
    "\n",
    "def test_ne(a,b,tst_name=''): test_eq(a,b,tst_name,False)\n",
    "\n",
    "def apply_all(*funcs): return reduce(lambda f,g: lambda x: f(g(x)), reversed(funcs), noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(noop(1),1)\n",
    "test_ne(2,1)\n",
    "test_eq(array([1,2]), array([1,2]))\n",
    "test_ne(array([1,2]), array([1]))\n",
    "test_eq(tensor([1,2]), tensor([1,2]))\n",
    "test_ne(tensor([1,2]), tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def listify(o):\n",
    "    \"Make `o` a list.\"\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if not isinstance(o, Iterable): return [o]\n",
    "    #Rank 0 tensors in PyTorch are Iterable but don't have a length.\n",
    "    try: a = len(o)\n",
    "    except: return [o]\n",
    "    return list(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(listify(None),[])\n",
    "test_eq(listify([1,2,3]),[1,2,3])\n",
    "test_ne(listify([1,2,3]),[1,2,])\n",
    "test_eq(listify('abc'),['abc'])\n",
    "test_eq(listify(range(0,3)),[0,1,2])\n",
    "test_eq(listify(tensor(0)),[tensor(0)])\n",
    "test_eq(listify([tensor(0),tensor(1)]),[tensor(0),tensor(1)])\n",
    "test_eq(listify(tensor([0.,1.1])),[0,1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def order_sorted(funcs, order_key='_order'):\n",
    "    key = lambda o: getattr(o, order_key, 0)\n",
    "    return sorted(listify(funcs), key=key)\n",
    "\n",
    "def apply_all(x, funcs, *args, order_key='_order', **kwargs):\n",
    "    \"Apply all `funcs` to `x` in order, pass along `args` and `kwargs`.\"\n",
    "    for f in order_sorted(funcs, order_key=order_key): x = f(x, *args, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# basic behavior\n",
    "def _test_f1(x, a=2): return x**a\n",
    "def _test_f2(x, a=2): return a*x\n",
    "test_eq(apply_all(2, [_test_f1, _test_f2]), 8)\n",
    "# order\n",
    "_test_f1._order = 1\n",
    "test_eq(apply_all(2, [_test_f1, _test_f2]), 16)\n",
    "#args\n",
    "test_eq(apply_all(2, [_test_f1, _test_f2], 3), 216)\n",
    "#kwargs\n",
    "test_eq(apply_all(2, [_test_f1, _test_f2], a=3), 216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def uniqueify(x, sort=False):\n",
    "    \"Return the unqiue elements in `x`, optionally `sort`-ed.\"\n",
    "    res = list(OrderedDict.fromkeys(x).keys())\n",
    "    if sort: res.sort()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(set(uniqueify([1,1,0,5,0,3])), {0,1,3,5})\n",
    "test_eq(uniqueify([1,1,0,5,0,3], sort=True), [0,1,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def setify(o): return o if isinstance(o,set) else set(listify(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(setify(None), set())\n",
    "test_eq(setify('abc'), {'abc'})\n",
    "test_eq(setify([1,2,2]), {1,2})\n",
    "test_eq(setify(range(0,3)), {0,1,2})\n",
    "test_eq(setify({1,2}), {1,2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def onehot(x, c):\n",
    "    \"Return the one-hot encoded tensor for `x` with `c` classes.\"\n",
    "    res = torch.zeros(c)\n",
    "    res[x] = 1.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(onehot(1,5), tensor([0.,1.,0.,0.,0.]))\n",
    "test_eq(onehot([1,3],5), tensor([0.,1.,0.,1.,0.]))\n",
    "test_eq(onehot(tensor([1,3]),5), tensor([0.,1.,0.,1.,0.]))\n",
    "test_eq(onehot([True,False,True,True,False],5), tensor([1.,0.,1.,1.,0.]))\n",
    "test_eq(onehot([],5), tensor([0.,0.,0.,0.,0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res\n",
    "\n",
    "def get_files(path, extensions=None, recurse=False, include=None):\n",
    "    \"Get all the files in `path` with optional `extensions`.\"\n",
    "    path = Path(path)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
    "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
    "            res += _get_files(p, f, extensions)\n",
    "        return res\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        return _get_files(path, f, extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "test_eq(len(get_files(path/'train'/'3')), 346)\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.png')), 346)\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg')), 0)\n",
    "test_eq(len(get_files(path/'train', extensions='.png')), 0)\n",
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True)), 709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, include=['train'])), 709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, include=['train', 'test'])), 729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def grab_idx(batch, i):\n",
    "    \"Return the `i`-th sample in `batch`\"\n",
    "    return [grab_idx(b,i) for b in batch] if isinstance(batch, (list,tuple)) else batch[i].detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(grab_idx(tensor([1,2]), 1), 2)\n",
    "test_eq(grab_idx([tensor([1,2]), tensor([3,4])], 1), [2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def read_column(df, col_name, prefix='', suffix='', delim=None):\n",
    "    \"Read `col_name` in `df`, optionnally adding `prefix` or `suffix`.\"\n",
    "    values = df[col_name].values.astype(str)\n",
    "    values = np.char.add(np.char.add(prefix, values), suffix)\n",
    "    if delim is not None:\n",
    "        values = np.array(list(csv.reader(values, delimiter=delim)))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "df = pd.DataFrame({'a': ['cat', 'dog', 'car'], 'b': ['a b', 'c d', 'a e']})\n",
    "test_eq(read_column(df, 'a'), np.array(['cat', 'dog', 'car']))\n",
    "test_eq(read_column(df, 'a', prefix='o'), np.array(['ocat', 'odog', 'ocar']))\n",
    "test_eq(read_column(df, 'a', suffix='.png'), np.array(['cat.png', 'dog.png', 'car.png']))\n",
    "test_eq(read_column(df, 'b', delim=' '), np.array([['a','b'], ['c','d'], ['a','e']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behing the scenes there is no more open/get method or processors that transforms our raw items to the tensors we feed the model but only transforms. \n",
    "\n",
    "One transform will open an image, once transform will convert it to RGB, one transform will resize it, one transform (actually two) will convert it to a tensor. For the labels, one transform will transform class name to an index. Or one list of labels to a one-hot encoded vector. That transformation is done in `__call__`.\n",
    "\n",
    "This means that some transforms need a preliminary step to get ready: for instance the transform that deal with labels needs to identify the different classes in the training set. We do this kind of things in the `setup` method.\n",
    "\n",
    "Also, for display purposes, some transforms need to be reversed: we want to display the class name and not the index of the class for instance. This is done in the `undo` method. Note that a lot of transforms won't need to implement that method: you don't want to undo opening the image or a data augmentation transform. However, you want to undo the one-hot encoding of labels, or the transform that puts the channel dimension at 1 because in both cases, you need this reveresed for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Transform():\n",
    "    \"A basic class to transform some data.\"\n",
    "    _order=0\n",
    "    def __call__(self, o):  return o\n",
    "    def undo(self, o):      return o\n",
    "    def setup(self, items): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then when we want to describe a class of items, we will specify default transforms that go with it: for instance, an `Image` will have a transforms that opens it by default. A `Cateogry` will have a transforms that encodes classes to index. This is given in the `default_tfms` argument (you give one or a list of `Transform` classes). `init_tfms` will initiliaze them.\n",
    "\n",
    "Why is there `default_tfms` and `default_tfms_xy`? Well that's because transforms can be applied at two different level: the item level (item being input or target) or the tuple (input,target) level. Why the separation and not just do the latter? (a transfrom that applies to input could be written as return (tfm(input), label) after all) That would break the flexibility of the data block API in which each `Item` class can be used as input or target. For instance an `Image` can be used as x or y, and in each case, it will have its default transform that opens it.\n",
    "\n",
    "Then why have `xy` transforms? Sometimes, you need to know things about the `x` to apply your transform to the `y` (or the opposite) so some transforms can only be written at that level. Note that if you specify a `default_tfms_xy` you break the data block API in the sense that your class of Item will only be able to be used as input or target. For instance, Bbox can only be used as target, as their transform `ScaleBbox` is a `xy` transform: it needs to know `x` (specifically its dimensions) to be able to be applied to `y`. \n",
    "\n",
    "Thos are very specific cases (but we need to handle them). In general, the transforms applied to the `xy` level will be the data augmentation ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Item():\n",
    "    \"A basic class for representing some data type.\"\n",
    "    default_tfms = None\n",
    "    default_tfms_xy = None\n",
    "    \n",
    "    def init_tfms(self, xy=False):\n",
    "        return [t() for t in listify(self.default_tfms_xy if xy else self.default_tfms)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data block API core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ItemList is a general class to contain all the items (item being input or target here). It's intended to be a final class. You initiliaze it with some `items`, `tfms`, `item_type` and some `tfm_kwargs`. When you access one (or several) element, `tfms` are applied to it with `kwargs` being passed. Their `_order` attribute determines in which order (note that we sort them at init because we need them in order for undo). Supported indexing includes int, collection of ints or boolean masks.\n",
    "\n",
    "To quickly get the `undo` method on all transforms applied to an object `o`, there is the `deproc` method. Note that the transforms `undo` methods are applied in the reverse order of the one transforms were applied, so that it can be chained properly.\n",
    "\n",
    "Lastly the `show` method will display the item in index `i` by indexing into it (which calls all transforms) then calling `deproc` on the result (which will reverse the transforms that need to be reversed) and calling the `show` method of `item_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ItemList():\n",
    "    def __init__(self, items, tfms=None, **tfm_kwargs):\n",
    "        self.items,self.tfms,self.tfm_kwargs = items,order_sorted(tfms),tfm_kwargs\n",
    "        for tfm in self.tfms: getattr(tfm, 'setup', noop)(self.items)\n",
    "    def _get(self, i): return apply_all(i, self.tfms, **self.tfm_kwargs)\n",
    "    def __getitem__(self, idx):\n",
    "        try: return self._get(self.items[idx])\n",
    "        except TypeError:\n",
    "            if isinstance(idx[0],bool):\n",
    "                assert len(idx)==len(self) # bool mask\n",
    "                return [self._get(o) for m,o in zip(idx,self.items) if m]\n",
    "            return [self._get(self.items[i]) for i in idx]\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return iter(self.items)\n",
    "    def __setitem__(self, i, o): self.items[i] = o\n",
    "    def __delitem__(self, i): del(self.items[i])\n",
    "    def __repr__(self):\n",
    "        res = f'{self.__class__.__name__} ({len(self)} items)\\n{self.items[:10]}'\n",
    "        if len(self)>10: res = res[:-1]+ '...]'\n",
    "        return res\n",
    "    \n",
    "    def deproc(self, o): \n",
    "        \"Reverse transforms on `o`.\"\n",
    "        return apply_all(o, [getattr(t, 'undo', noop) for t in reversed(self.tfms)], **self.tfm_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "def add(x, a=1): return x+a\n",
    "def multiply(x, a=2): return x*a\n",
    "def square(x): return x**2\n",
    "\n",
    "#tfms can be basic functions\n",
    "il = ItemList([0,1,2,3], tfms=[add, multiply, square])\n",
    "#Test indexing\n",
    "test_eq(il[1], ((1+1) * 2) ** 2)\n",
    "test_eq(il[1,2,3], [(((x+1) * 2) ** 2) for x in [1,2,3]])\n",
    "test_eq(il[True,False,False,True], [(((x+1) * 2) ** 2) for x in [0,3]])\n",
    "\n",
    "#Test _order\n",
    "square._order = 0\n",
    "multiply._order = 1\n",
    "add._order = 2\n",
    "il = ItemList([0,1,2,3], tfms=[add, multiply, square])\n",
    "test_eq(il[2], ((2**2) * 2) + 1)\n",
    "\n",
    "#Test kwargs\n",
    "il = ItemList([0,1,2,3], tfms=[add, multiply], a=3)\n",
    "test_eq(il[2], (2 * 3) + 3)\n",
    "\n",
    "#Test undo\n",
    "def add_undo(x, a=1): return x-a\n",
    "def multiply_undo(x, a=2): return x/a\n",
    "add.undo = add_undo\n",
    "multiply.undo = multiply_undo\n",
    "il = ItemList([0,1,2,3], tfms=[add, multiply, square])\n",
    "test_eq(il.deproc(9), (9-1)/2)\n",
    "il = ItemList([0,1,2,3], tfms=[add, multiply], a=3)\n",
    "test_eq(il.deproc(9), (9-3)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To contain the tuples (x,y) we use the following class. It's initialized with two `ItemList` `x` and `y`, with a set of `tfms` and some `tfm_kwargs`. When accessing an index, it returns the result of the transforms applied to the corresponding (x,y)  with the `tfm_kwargs` (which are again sorted by their `_order` key in the init). \n",
    "\n",
    "Like in an `ItemList`, `deproc` will call `undo` on all transforms in reverse order, so first the transforms of this object, then the transforms on the `x` and `y` ItemList level. \n",
    "\n",
    "The `show` method will display the `x` and `y` at a given index on a given `ax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LabeledData():\n",
    "    def __init__(self, x, y, tfms=None, **tfm_kwargs): \n",
    "        self.x,self.y,self.tfms,self.tfm_kwargs = x,y,order_sorted(tfms),tfm_kwargs\n",
    "        for tfm in listify(self.tfms): getattr(tfm, 'setup', noop)(self)\n",
    "    def __repr__(self):        return f'{self.__class__.__name__}\\nx: {self.x}\\ny: {self.y}\\n'\n",
    "    def __getitem__(self,idx): return apply_all((self.x[idx],self.y[idx]), self.tfms, **self.tfm_kwargs)\n",
    "    def __len__(self):         return len(self.x)\n",
    "    \n",
    "    def deproc(self, o):\n",
    "        \"Reverse transforms on `o`.\"\n",
    "        (x,y) = apply_all(o, [getattr(t, 'undo', noop) for t in reversed(self.tfms)], **self.tfm_kwargs)\n",
    "        return (self.x.deproc(x),self.y.deproc(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "def add_sub(o, a=2): return (o[0]-a, o[1]+a)\n",
    "x = ItemList([0,1,2,3], tfms=[multiply, square])\n",
    "y = ItemList([0,1,2,3], tfms=[add, multiply])\n",
    "ld = LabeledData(x, y, tfms=add_sub)\n",
    "test_eq(ld[2], ((2**2) * 2 - 2, (2*2 + 1) + 2))\n",
    "\n",
    "ld = LabeledData(x, y, tfms=add_sub, a=3)\n",
    "test_eq(ld[2], ((2**2) * 2 - 3, (2*2 + 1) + 3))\n",
    "\n",
    "def undo_add_sub(o, a=2): return (o[0]+a, o[1]-a)\n",
    "ld = LabeledData(x, y, tfms=add_sub)\n",
    "test_eq(ld.deproc((8,6)), (8/2, (6-1)/2))\n",
    "\n",
    "add_sub.undo = undo_add_sub\n",
    "ld = LabeledData(x, y, tfms=add_sub)\n",
    "test_eq(ld.deproc((8,6)), ((8+2)/2, ((6-2) - 1)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageOpener(Transform):\n",
    "    def __call__(self, o): return PIL.Image.open(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Image(Item):\n",
    "    default_tfms = ImageOpener\n",
    "    def __init__(self, cmap=None, alpha=1.): self.cmap,self.alpha = cmap,alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryEncoder(Transform):\n",
    "    \"Encodes a categorical variable to index.\"\n",
    "    def __init__(self): self.vocab=None\n",
    "    \n",
    "    def setup(self, items):\n",
    "        if self.vocab is not None: return\n",
    "        self.vocab = uniqueify(items, sort=True)\n",
    "        self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "    \n",
    "    def __call__(self, o): return self.otoi[o]\n",
    "    def undo(self, i):    return self.vocab[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Category(Item):\n",
    "    default_tfms = CategoryEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = CategoryEncoder()\n",
    "#Even if 'dog' is the first class, vocab is sorted for reproducibility\n",
    "tfm.setup(['dog', 'cat', 'cat', 'dog', 'cat', 'dog'])\n",
    "test_eq(tfm.vocab,['cat', 'dog'])\n",
    "test_eq([tfm(o) for o in ['dog', 'cat', 'cat']], [1,0,0])\n",
    "test_eq(tfm('cat'),0)\n",
    "test_eq(tfm.undo(1),'dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_image_files(path, include=None):\n",
    "    \"Get image files in `path` recursively.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=True, include=include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "test_eq(len(get_image_files(path)),1428)\n",
    "test_eq(len(get_image_files(path/'train')),709)\n",
    "test_eq(len(get_image_files(path, include='train')),709)\n",
    "test_eq(len(get_image_files(path, include=['train','valid'])),1408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def random_splitter(items, valid_pct=0.2, seed=None):\n",
    "    \"Split `items` between train/val with `valid_pct` randomly.\"\n",
    "    if seed is not None: torch.manual_seed(seed)\n",
    "    rand_idx = torch.randperm(len(items))\n",
    "    cut = int(valid_pct * len(items))\n",
    "    return rand_idx[cut:],rand_idx[:cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "trn,val = random_splitter([0,1,2,3,4,5], seed=42)\n",
    "test_eq(trn, tensor([3, 2, 4, 1, 5]))\n",
    "test_eq(val, tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_mask(items, name):\n",
    "    return [(o.parent.parent.name if isinstance(o, Path) else o.split(os.path.sep)[-2]) == name for o in items]\n",
    "\n",
    "def grandparent_splitter(items, train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    return _grandparent_mask(items, train_name),_grandparent_mask(items, valid_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#With string filenames\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = [path/'train'/'3'/'9932.png', path/'valid'/'7'/'7189.png', \n",
    "         path/'valid'/'7'/'7320.png', path/'train'/'7'/'9833.png',  \n",
    "         path/'train'/'3'/'7666.png', path/'valid'/'3'/'925.png',\n",
    "         path/'train'/'7'/'724.png', path/'valid'/'3'/'93055.png']\n",
    "trn,val = grandparent_splitter(items)\n",
    "test_eq(trn,[True,False,False,True,True,False,True,False])\n",
    "test_eq(val,[False,True,True,False,False,True,False,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_labeller(items):\n",
    "    \"Label `items` with the parent folder name.\"\n",
    "    return [o.parent.name if isinstance(o, Path) else o.split(os.path.sep)[-1] for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(parent_labeller(items),['3','7','7','7','3','3','7','3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def func_labeller(items, func):\n",
    "    \"Label `items` according to `func`.\"\n",
    "    return [func(o) for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(func_labeller(items, lambda x: int(x.parent.name)+1),[4,8,8,8,4,4,8,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def re_labeller(items, pat):\n",
    "    \"Label `items` with a regex `pat`.\"\n",
    "    pat = re.compile(pat)\n",
    "    def _inner(o):\n",
    "        res = pat.search(str(o))\n",
    "        assert res,f'Failed to find \"{pat}\" in \"{o}\"'\n",
    "        return res.group(1)\n",
    "    return func_labeller(items, _inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "pat = re.compile(r'/([^/]+)/\\d+.png$')\n",
    "test_eq(re_labeller(items, pat),['3','7','7','7','3','3','7','3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integration test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "items = get_image_files(path/'images')\n",
    "splits = random_splitter(items)\n",
    "labels = re_labeller(items, pat = r'/([^/]+)_\\d+.jpg$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the data in train valid, we use a basic ItemList for fancy indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ItemList(items)\n",
    "labels = ItemList(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the xs we need to use the image opener transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid = map(lambda s: ItemList(items[s], tfms=ImageOpener()), splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ys we need to use the category encoder transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_valid = map(lambda s: ItemList(labels[s], tfms=CategoryEncoder()), splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can construct our training and validation LabeledData objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = LabeledData(x_train, y_train)\n",
    "valid = LabeledData(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,i = train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,cls = train.deproc(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(1,1)\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "ax.set_title(cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(x, ax=None):\n",
    "    if ax is None: _,ax = plt.subplots(1,1)\n",
    "    ax.imshow(x)\n",
    "    ax.axis('off')\n",
    "    \n",
    "def show_cat(x, ax=None):\n",
    "    if ax is None: print(x)\n",
    "    else: ax.set_title(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cat(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(ld, idx, show_x, show_y, **kwargs):\n",
    "    (x,y) = ld.deproc(ld[idx])\n",
    "    show_x(x, **kwargs)\n",
    "    show_y(y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(1,1)\n",
    "display(train, 0, show_img, show_cat, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Item class has default transforms (no need to pass ImageOpener() for Image) and can have a show method (that we can always replace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Image(Item):\n",
    "    default_tfms = ImageOpener\n",
    "    \n",
    "    def show(self, x, ax=None, cmap=None, alpha=1):\n",
    "        if ax is None: _,ax = plt.subplots(1,1)\n",
    "        ax.imshow(x, cmap=cmap, alpha=alpha)\n",
    "        ax.axis('off')\n",
    "        return {'ax': ax}\n",
    "\n",
    "class Category(Item):\n",
    "    default_tfms = CategoryEncoder\n",
    "    def show(self, x, ax): ax.set_title(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(ld, idx, types, show_x=None, show_y=None, **kwargs):\n",
    "    (x,y) = ld.deproc(ld[idx])\n",
    "    if show_x is None: show_x = types[0].show\n",
    "    if show_y is None: show_y = types[1].show\n",
    "    support = show_x(x, **kwargs)\n",
    "    if support is None: support = {}\n",
    "    show_y(y, **{**kwargs, **support})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train, 0, (Image(),Category()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main class to represent any kind of data. User provides the type of inputs/targets in `type_cls`. Then they implement the four functions to gather the data:\n",
    "- `get_source` returns the source of the data after potentially downloading it.\n",
    "- `get_items` takes the source and retun the list of all items\n",
    "- `split` take the items and returns two (or more) list of indices or boolean masks that explain how to split the data in train and valid (potentially valids) set.\n",
    "- `label` take the items and returns a list of targets.\n",
    "\n",
    "Then during the intilialization, the `source` is fetched by calling `get_source`, which then allows to collect the items (with `get_items`), the different splits (with `split`) and the labels (with `label`). Default transforms for `x` and `y` are collected (they can be overriden by a custom `tfms_x` or `tfms_y` passed to the init) and the different ItemList for each split x/y are created.\n",
    "\n",
    "Then the default transforms for `xy` are collected by looking at the types of x and y (they can be overriden by a custom `tfms_xy` passed to the init), the `tfms` passed are added, and the xs/ys are grouped in the various datasets (which are all `LabeledData`). The `tfm_kwargs` are passed at this level only (so they'll only be passed along to xy transforms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBlock():\n",
    "    \"Main class to represent a dataset. Subclass the 2 properties and 4 methods below to your need.\"\n",
    "    type_cls = (Item,Item) #Type of input,target\n",
    "    def get_source(self):         \n",
    "        \"Return the source of your data (path, dataframe...), optionally download it.\"\n",
    "        raise NotImplementedError\n",
    "    def get_items(self, source):  \n",
    "        \"Use `source` to return the list of all items.\"\n",
    "        raise NotImplementedError\n",
    "    def split(self, items):       \n",
    "        \"Explain how so split the `items`. Return two (or more) lists of indices/boolean masks.\"\n",
    "        raise NotImplementedError\n",
    "    def label(self, items):       \n",
    "        \"Explain how to label your `items`. Return a list of labels.\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __init__(self, tfms=None, tfms_x=None, tfms_y=None, tfms_xy=None, **tfm_kwargs):\n",
    "        self.source = self.get_source()\n",
    "        items = ItemList(self.get_items(self.source)) #Just for fancy indexing\n",
    "        split_idx = self.split(items)\n",
    "        labels = ItemList(self.label(items))          #Just for fancy indexing\n",
    "        self.types = self.type_cls[0](),self.type_cls[1]()\n",
    "        if tfms_x is None: tfms_x = self.types[0].init_tfms()\n",
    "        if tfms_y is None: tfms_y = self.types[1].init_tfms()\n",
    "        xs = map(lambda o: ItemList(items[o],  tfms=tfms_x), split_idx)\n",
    "        ys = map(lambda o: ItemList(labels[o], tfms=tfms_y), split_idx)\n",
    "        if tfms_xy is None: tfms_xy = self.types[0].init_tfms(xy=True) + self.types[1].init_tfms(xy=True)\n",
    "        self.datasets = [LabeledData(x, y, tfms=listify(tfms) + tfms_xy, **tfm_kwargs) \n",
    "                         for (x,y) in zip(xs, ys)]\n",
    "        \n",
    "    @property\n",
    "    def train(self): return self.datasets[0]\n",
    "    @property\n",
    "    def valid(self): return self.datasets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetsData(DataBlock):\n",
    "    type_cls = (Image, Category)\n",
    "    \n",
    "    def get_source(self):        return untar_data(URLs.PETS)\n",
    "    def get_items(self, source): return get_image_files(source/\"images\")\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):      return re_labeller(items, pat = r'/([^/]+)_\\d+.jpg$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PetsData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.train, 1, data.types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "TfmY = Enum('TfmY', 'No Mask Image Point Bbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageTransform(Transform): \n",
    "    \"Basic class for data augmentation transforms.\"\n",
    "    _order=0\n",
    "    _tfm_y_func={TfmY.Image: 'apply_img',   TfmY.Mask: 'apply_mask', TfmY.No: 'noop',\n",
    "                 TfmY.Point: 'apply_point', TfmY.Bbox: 'apply_bbox'}\n",
    "    _undo_y_func={TfmY.Image: 'unapply_img',   TfmY.Mask: 'unapply_mask', TfmY.No: 'noop',\n",
    "                  TfmY.Point: 'unapply_point', TfmY.Bbox: 'unapply_bbox'}\n",
    "    \n",
    "    def apply(self, x):       return x\n",
    "    def apply_img(self, y):   return self.apply(y)\n",
    "    def apply_mask(self, y):  return self.apply_img(y)\n",
    "    def apply_point(self, y): return y\n",
    "    def apply_bbox(self, y):  return self.apply_point(y)\n",
    "    \n",
    "    def randomize(self): pass\n",
    "    \n",
    "    def __call__(self, o, tfm_y=TfmY.No):\n",
    "        (x,y) = o\n",
    "        self.x = x #Saves the x in case it's needed in the apply for y (x.size for apply_point for instance)\n",
    "        self.randomize() #Ensures we have the same state for x and y\n",
    "        return self.apply(x),getattr(self, self._tfm_y_func[tfm_y], noop)(y)\n",
    "    \n",
    "    def unapply(self, x):       return x\n",
    "    def unapply_img(self, y):   return self.unapply(y)\n",
    "    def unapply_mask(self, y):  return self.unapply_img(y)\n",
    "    def unapply_point(self, y): return y\n",
    "    def unapply_bbox(self, y):  return self.unapply_point(y)\n",
    "    \n",
    "    def undo(self, o, tfm_y=TfmY.No):\n",
    "        (x,y) = o\n",
    "        return self.unapply(x),getattr(self, self._undo_y_func[tfm_y], noop)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DecodeImg(ImageTransform):\n",
    "    \"Convert regular image to RGB, masks to L mode.\"\n",
    "    def __init__(self, mode_x='RGB', mode_y=None):\n",
    "        self.mode_x,self.mode_y = mode_x,mode_y\n",
    "        \n",
    "    def apply(self, x):       return x.convert(self.mode_x)\n",
    "    def apply_image(self, y): return y.convert(self.mode_x if self.mode_y is None else self.mode_y)\n",
    "    def apply_mask(self, y):  return y.convert('L' if self.mode_y is None else self.mode_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResizeFixed(ImageTransform):\n",
    "    \"Resize image to `size` using `mode_x` (and `mode_y` on targets).\"\n",
    "    _order=10\n",
    "    def __init__(self, size, mode_x=PIL.Image.BILINEAR, mode_y=None):\n",
    "        if isinstance(size,int): size=(size,size)\n",
    "        size = (size[1],size[0]) #PIL takes size in the otherway round\n",
    "        self.size,self.mode_x,self.mode_y = size,mode_x,mode_y\n",
    "        \n",
    "    def apply(self, x):       return x.resize(self.size, self.mode_x)\n",
    "    def apply_image(self, y): return y.resize(self.size, self.mode_x if self.mode_y is None else self.mode_y)\n",
    "    def apply_mask(self, y):  return y.resize(self.size, PIL.Image.NEAREST if self.mode_y is None else self.mode_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToByteTensor(ImageTransform):\n",
    "    \"Transform our items to byte tensors.\"\n",
    "    _order=20\n",
    "    \n",
    "    def apply(self, x):\n",
    "        res = torch.ByteTensor(torch.ByteStorage.from_buffer(x.tobytes()))\n",
    "        w,h = x.size\n",
    "        return res.view(h,w,-1).permute(2,0,1)\n",
    "    \n",
    "    def unapply(self, x): return x[0] if x.shape[0] == 1 else x.permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToFloatTensor(ImageTransform):\n",
    "    \"Transform our items to float tensors (int in the case of mask).\"\n",
    "    _order=20\n",
    "    def __init__(self, div_x=255., div_y=None): self.div_x,self.div_y = div_x,div_y\n",
    "    def apply(self, x):      return x.float().div_(self.div_x)\n",
    "    def apply_mask(self, x): \n",
    "        return x.long() if self.div_y is None else x.long().div_(self.div_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [DecodeImg(), ResizeFixed(128), ToByteTensor(), ToFloatTensor()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integration test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PetsData(tfms=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.train, 1, data.types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader and DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "def get_dl(ds, bs, shuffle=False, drop_last=False, **kwargs):\n",
    "    \"Basic function to get a `DataLoader`\"\n",
    "    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=drop_last, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBunch():\n",
    "    \"Basic wrapper around several `DataLoader`.\"\n",
    "    def __init__(self, *dls, types=None):\n",
    "        self.dls,self.types = dls,types\n",
    "        \n",
    "    def show_batch(self, dl_idx=0, items=9, show_xy=None, show_x=None, show_y=None):\n",
    "        if show_x is None:  show_x  = self.types[0].show\n",
    "        if show_y is None:  show_y  = self.types[1].show\n",
    "        if show_xy is None: show_xy = self.types[0].show_xy\n",
    "        xb, yb = next(iter(self.dl[dl_idx]))\n",
    "         = [self.dl[dl_idx].dataset.]\n",
    "        \n",
    "    @property\n",
    "    def train_dl(self): return self.dls[0]\n",
    "    @property\n",
    "    def valid_dl(self): return self.dls[1]\n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _db_databunch(self, bs=64, **kwargs):\n",
    "    dls = [get_dl(ds, bs, shuffle=(i==0), drop_last=(i==0), **kwargs) for ds in self.datasets]\n",
    "    return DataBunch(*dls, types=self.types)\n",
    "\n",
    "DataBlock.databunch = _db_databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistData(DataBlock):\n",
    "    x_cls = Image\n",
    "    y_cls = Category\n",
    "    \n",
    "    def get_source(self):        return untar_data(URLs.MNIST)\n",
    "    def get_items(self, source): return get_image_files(source)\n",
    "    def split(self, items):      return grandparent_splitter(items, train_name='training', valid_name='testing')\n",
    "    def label(self, items):      return parent_labeller(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData(tfms=[ToByteTensor(), ToFloatTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cmap is specified in the `item_type` for inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.x.item_type.cmap='gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PLANET_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiCategoryEncoder(Transform):\n",
    "    \"Encodes a categorical variable to index.\"\n",
    "    def __init__(self, do_encode=True, classes=None): \n",
    "        assert do_encode or classes is not None, \"If you use one_hot encoded items, please provide classes.\"\n",
    "        self.vocab,self.do_encode=None,do_encode\n",
    "        self.vocab = classes\n",
    "    \n",
    "    def setup(self, items):\n",
    "        if self.vocab is not None: return\n",
    "        vocab = set()\n",
    "        for c in items: vocab = vocab.union(set(c))\n",
    "        self.vocab = list(vocab)\n",
    "        self.vocab.sort()\n",
    "        self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "    \n",
    "    def __call__(self, item): \n",
    "        if not self.do_encode: return item\n",
    "        return onehot([self.otoi[o] for o in item if o in self.otoi], len(self.vocab))\n",
    "    \n",
    "    def undo(self, o): return [self.vocab[i] for i,v in enumerate(o) if v==1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategory(Item):\n",
    "    default_tfms = MultiCategoryEncoder\n",
    "    def show(self, x, ax): ax.set_title(';'.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "tfm = MultiCategoryEncoder()\n",
    "#Even if 'c' is the first class, vocab is sorted for reproducibility\n",
    "tfm.setup([['c','a'], ['a','b'], ['b']])\n",
    "test_eq(tfm.vocab,['a','b','c'])\n",
    "\n",
    "test_eq(tfm(['b','a']),tensor([1.,1.,0.]))\n",
    "test_eq(tfm.undo(tensor([1.,0.,1.])),['a','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanetData(DataBlock):\n",
    "    x_cls = Image\n",
    "    y_cls = MultiCategory\n",
    "    \n",
    "    def get_source(self):        \n",
    "        self.path = untar_data(URLs.PLANET_SAMPLE)\n",
    "        return pd.read_csv(path/'labels.csv')\n",
    "    def get_items(self, source): return read_column(source, 'image_name', prefix=f'{self.path}/train/', suffix='.jpg')\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):      return read_column(self.source, 'tags', delim=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PlanetData(tfms=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.show(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = data.train.y.tfms[0].vocab\n",
    "otoi = {s:i for i,s in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanetData1(DataBlock):\n",
    "    x_cls = Image\n",
    "    y_cls = MultiCategory\n",
    "    \n",
    "    def get_source(self):        \n",
    "        self.path = untar_data(URLs.PLANET_SAMPLE)\n",
    "        return pd.read_csv(path/'labels.csv')\n",
    "    def get_items(self, source): return read_column(source, 'image_name', prefix=f'{self.path}/train/', suffix='.jpg')\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):  \n",
    "        #This is just for the sake of using one-hot encoded labels, but imagine we have a dataset where it's the case.\n",
    "        tags = read_column(self.source, 'tags', delim=' ')\n",
    "        labels = []\n",
    "        for t in tags:\n",
    "            x = torch.zeros(len(classes))\n",
    "            idx = [otoi.get(l,None) for l in t]\n",
    "            idx = [i for i in idx if i is not None]\n",
    "            x[idx] = 1.\n",
    "            labels.append(x)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PlanetData1(tfms=tfms, tfms_y=MultiCategoryEncoder(do_encode=False, classes=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.show(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camvid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SegmentMask(Image):\n",
    "    \"An `ItemGetter` for segmentation mask targets.\"\n",
    "    def __init__(self, cmap='tab20', alpha=0.5): \n",
    "        super().__init__(cmap=cmap, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamvidData(DataBlock):\n",
    "    x_cls = Image\n",
    "    y_cls = SegmentMask\n",
    "    \n",
    "    def get_source(self):        return untar_data(URLs.CAMVID_TINY)      \n",
    "    def get_items(self, source): return get_image_files(source/'images')\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):      \n",
    "        path_lbl = self.source/'labels'\n",
    "        codes = np.loadtxt(self.source/'codes.txt', dtype=str)\n",
    "        return func_labeller(items, lambda x: path_lbl/f'{x.stem}_P{x.suffix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CamvidData(tfms=tfms, tfm_y=TfmY.Mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.show(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biwii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointScaler(Transform):\n",
    "    _order = -10 #Run before we apply any ImageTransform\n",
    "    def __init__(self, do_scale=True, y_first=False): \n",
    "        self.do_scale,self.y_first = do_scale,y_first\n",
    "    \n",
    "    def __call__(self, o, tfm_y=TfmY.No):\n",
    "        (x,y) = o\n",
    "        if not isinstance(y, torch.Tensor): y = tensor(y)\n",
    "        y = y.view(-1, 2).float()\n",
    "        if not self.y_first: y = y.flip(1)\n",
    "        if self.do_scale: y = y * 2/tensor(list(x.size)).float() - 1\n",
    "        return (x,y)\n",
    "    \n",
    "    def undo(self, o, tfm_y=TfmY.No):\n",
    "        (x,y) = o\n",
    "        y = y.flip(1)\n",
    "        y = (y + 1) * tensor([x.shape[:2]]).float()/2\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Points(Item):\n",
    "    default_tfms_xy = PointScaler\n",
    "    \n",
    "    def show(self, x, ax):\n",
    "        params = {'s': 10, 'marker': '.', 'c': 'r'}\n",
    "        ax.scatter(x[:,1], x[:,0], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeImg():\n",
    "    def __init__(self, size): self.size,self.shape = size,(size[1],size[0])\n",
    "\n",
    "il = ItemList([[0,0], [120,0], [0,200], [120,200], [60,100]], item_type=Points())\n",
    "#At the ItemList level, there is no transform happening.\n",
    "test_eq(il[1], [120,0])\n",
    "#The transform is applied when getting the items at the xy level.\n",
    "ll = LabeledData(ItemList([FakeImg((200,120)) for _ in range(5)]), il, tfms=PointScaler())\n",
    "test_eq(ll[1][1], tensor([[-1., 1.]]))\n",
    "test_eq(ll[4][1], tensor([[0., 0.]]))\n",
    "o = ll[2]\n",
    "#Test deproc undoes the scaling and switching\n",
    "test_eq(ll.deproc(o)[1], tensor([[0., 200.]]))\n",
    "\n",
    "#Giving scaled points\n",
    "il1 = ItemList([[-1.,-1.], [1.,-1.], [-1.,1.], [1.,1.], [0.,0.]], item_type=Points())\n",
    "ll1 = LabeledData(ItemList([FakeImg((200,120)) for _ in range(5)]), il1, tfms=PointScaler(do_scale=False))\n",
    "for i in range(5): \n",
    "    o,o1 = ll[i],ll1[i]\n",
    "    test_eq(o[1], o1[1])\n",
    "    test_eq(ll.deproc(o)[1], ll1.deproc(o1)[1])\n",
    "    \n",
    "#Giving scaled points with y_first=True\n",
    "il2 = ItemList([[-1.,-1.], [-1.,1.], [1.,-1.], [1.,1.], [0.,0.]], item_type=Points())\n",
    "ll2 = LabeledData(ItemList([FakeImg((200,120)) for _ in range(5)]), il2, tfms=PointScaler(do_scale=False, y_first=True))\n",
    "for i in range(5): \n",
    "    o,o2 = ll[i],ll2[i]\n",
    "    test_eq(o[1], o2[1])\n",
    "    test_eq(ll.deproc(o)[1], ll2.deproc(o2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiwiData(DataBlock):\n",
    "    x_cls = Image\n",
    "    y_cls = Points\n",
    "    \n",
    "    def get_source(self):        return untar_data(URLs.BIWI_SAMPLE)      \n",
    "    def get_items(self, source): return get_image_files(source/'images')\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):      \n",
    "        fn2ctr = pickle.load(open(self.source/'centers.pkl', 'rb'))\n",
    "        return func_labeller(items, lambda o:fn2ctr[o.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = BiwiData(tfms=tfms, tfm_y=TfmY.Point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.data import get_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBoxScaler(PointScaler):\n",
    "     \n",
    "    def __call__(self, o, tfm_y=TfmY.Bbox): \n",
    "        (x,y) = o\n",
    "        return x, (super().__call__((x,y[0])).view(-1,4),y[1])\n",
    "    def undo(self, o, tfm_y=TfmY.Bbox):     \n",
    "        (x,y) = o\n",
    "        _,bbox = super().undo((x,y[0].view(-1,2)))\n",
    "        return x, (bbox.view(-1,4),y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBoxEncoder(MultiCategoryEncoder):\n",
    "    def setup(self, items):\n",
    "        if self.vocab is not None: return\n",
    "        super().setup([c[1] for c in items])\n",
    "        self.vocab.insert(0, 'background')\n",
    "        self.otoi  = {v:k for k,v in enumerate(self.vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "def _draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def _draw_rect(ax, b, color='white', text=None, text_size=14):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=color, lw=2))\n",
    "    _draw_outline(patch, 4)\n",
    "    if text is not None:\n",
    "        patch = ax.text(*b[:2], text, verticalalignment='top', color=color, fontsize=text_size, weight='bold')\n",
    "        _draw_outline(patch,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BBox(Item):\n",
    "    default_tfm = BBoxEncoder\n",
    "    default_tfm_xy = BBoxScaler\n",
    "     \n",
    "    def show(self, x, ax):\n",
    "        bbox,label = x\n",
    "        for b,l in zip(bbox, label): \n",
    "            if l != 'background': _draw_rect(ax, [b[1],b[0],b[3]-b[1],b[2]-b[0]], text=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def bb_pad_collate(samples, pad_idx=0):\n",
    "    \"Collate function for bounding boxes targets.\"\n",
    "    max_len = max([len(s[1][1]) for s in samples])\n",
    "    bboxes = torch.zeros(len(samples), max_len, 4)\n",
    "    labels = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    imgs = []\n",
    "    for i,s in enumerate(samples):\n",
    "        imgs.append(s[0][None])\n",
    "        bbs, lbls = s[1]\n",
    "        if not (bbs.nelement() == 0):\n",
    "            bboxes[i,-len(lbls):] = bbs\n",
    "            labels[i,-len(lbls):] = tensor(lbls)\n",
    "    return torch.cat(imgs,0), (bboxes,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoData(DataBlock):\n",
    "    x_cls = Image\n",
    "    y_cls = BBox\n",
    "    \n",
    "    def get_source(self):        return untar_data(URLs.COCO_TINY)      \n",
    "    def get_items(self, source): return get_image_files(source/'train')\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):      \n",
    "        images, lbl_bbox = get_annotations(self.source/'train.json')\n",
    "        img2bbox = dict(zip(images, lbl_bbox))\n",
    "        return func_labeller(items, lambda o:img2bbox[o.name])\n",
    "    \n",
    "    def databunch(self, bs=64, **kwargs):\n",
    "        kwargs['collate_fn'] = bb_pad_collate\n",
    "        return super().databunch(bs=bs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CocoData(tfms=tfms, tfm_y=TfmY.Bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python notebook2script.py \"200_datablock_config.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
