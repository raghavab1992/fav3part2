{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from exp.nb_02 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 02a_why_sqrt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalize(x, m, s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 1, 28, 28]), torch.Size([10000, 1, 28, 28]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "train_mean,train_std = x_train.mean(),x_train.std()\n",
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_valid = normalize(x_valid, train_mean, train_std)\n",
    "\n",
    "x_train = x_train.view(-1,1,28,28)\n",
    "x_valid = x_valid.view(-1,1,28,28)\n",
    "x_train.shape,x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def stats(x): return x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(-6.2598e-06), tensor(1.)), (tensor(-0.0059), tensor(0.9924)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(x_train), stats(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 1\n"
     ]
    }
   ],
   "source": [
    "n, c, *_ = x_train.shape\n",
    "print(n, c)\n",
    "\n",
    "l1 = nn.Conv2d(in_channels=c, out_channels=32, kernel_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def f1(x, a=0): return F.leaky_relu(l1(x), a)\n",
    "def f2(x, a=0): return F.leaky_relu(l1(x), a)-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# stats(l1.weight), stats(l1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(0.0930, grad_fn=<MeanBackward1>),\n",
       "  tensor(1.6379, grad_fn=<StdBackward0>)),\n",
       " (tensor(0.5932, grad_fn=<MeanBackward1>),\n",
       "  tensor(1.1778, grad_fn=<StdBackward0>)),\n",
       " (tensor(0.0932, grad_fn=<MeanBackward1>),\n",
       "  tensor(1.1778, grad_fn=<StdBackward0>)))"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = l1(x_train[:1000])\n",
    "a2 = f1(x_train[:1000])\n",
    "a3 = f2(x_train[:1000])\n",
    "stats(a1), stats(a2), stats(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 5, 5]), torch.Size([32]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.weight.shape, l1.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nn.modules.conv._ConvNd.reset_parameters??\n",
    "# nn.Conv2d??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "init??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 5, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 800)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf, ni, *_ = l1.weight.shape\n",
    "fan_in, fan_out = l1.weight[0][0].numel()*ni, l1.weight[0][0].numel()*nf \n",
    "fan_in, fan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gain(a=0): return math.sqrt(2./(1+a**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4142135623730951, 1.0, 0.5773502691896257, 1.4141428569978354)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain(0), gain(1.), gain(math.sqrt(5.)), gain(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773502691896258"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(10000).uniform_(-1,1).std()\n",
    "1/math.sqrt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_kaiming_unif(w, a=0):\n",
    "    g = gain(a)\n",
    "    nf, ni, *_ = w.shape\n",
    "    fan_in, fan_out = w[0][0].numel()*ni, w[0][0].numel()*nf \n",
    "    std = g*math.sqrt(3.)/math.sqrt(fan_in)\n",
    "    with torch.no_grad():\n",
    "        w.data.uniform_(-std, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.0479, grad_fn=<MeanBackward1>), tensor(1.1573, grad_fn=<StdBackward0>))\n",
      "(tensor(0.0357, grad_fn=<MeanBackward1>), tensor(0.6040, grad_fn=<StdBackward0>))\n"
     ]
    }
   ],
   "source": [
    "l1 = nn.Conv2d(in_channels=c, out_channels=32, kernel_size=5)\n",
    "init_kaiming_unif(l1.weight, a=1)\n",
    "print(stats(l1(x_train[:10000])))\n",
    "init_kaiming_unif(l1.weight, a=math.sqrt(5))\n",
    "print(stats(l1(x_train[:10000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.4712, grad_fn=<MeanBackward1>), tensor(0.8679, grad_fn=<StdBackward0>))\n",
      "(tensor(-0.0288, grad_fn=<MeanBackward1>), tensor(0.8679, grad_fn=<StdBackward0>))\n",
      "(tensor(-0.2765, grad_fn=<MeanBackward1>), tensor(1.0588, grad_fn=<StdBackward0>))\n",
      "(tensor(-0.7765, grad_fn=<MeanBackward1>), tensor(1.0588, grad_fn=<StdBackward0>))\n",
      "(tensor(-0.0237, grad_fn=<MeanBackward1>), tensor(0.9902, grad_fn=<StdBackward0>))\n",
      "(tensor(-0.5237, grad_fn=<MeanBackward1>), tensor(0.9902, grad_fn=<StdBackward0>))\n",
      "(tensor(0.5179, grad_fn=<MeanBackward1>), tensor(1.0137, grad_fn=<StdBackward0>))\n",
      "(tensor(0.0179, grad_fn=<MeanBackward1>), tensor(1.0137, grad_fn=<StdBackward0>))\n"
     ]
    }
   ],
   "source": [
    "l1 = nn.Conv2d(in_channels=c, out_channels=32, kernel_size=5)\n",
    "for a in [0, math.sqrt(5), 1, 0.01]:\n",
    "    init_kaiming_unif(l1.weight, a)\n",
    "    print(stats(F.leaky_relu(l1(x_train[:1000]), a)))\n",
    "    print(stats(f2(x_train[:1000], a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Trying on a small convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module): \n",
    "    def forward(self, x): return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a=0\n",
    "m = nn.Sequential(nn.Conv2d(1, 8, 3, 1), nn.LeakyReLU(a),\n",
    "                  nn.Conv2d(8, 16, 3, 1), nn.LeakyReLU(a),\n",
    "                  nn.Conv2d(16, 32, 3, 1), nn.LeakyReLU(a),\n",
    "                  nn.Conv2d(32, 1, 3, 1), nn.LeakyReLU(a),\n",
    "                  nn.AdaptiveAvgPool2d(1),\n",
    "                  Flatten()\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0552, grad_fn=<MeanBackward1>),\n",
       " tensor(0.0177, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = m(x_train[:1000])\n",
    "stats(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for l in m:\n",
    "    if isinstance(l, nn.Conv2d):\n",
    "        init_kaiming_unif(l.weight, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5145, grad_fn=<MeanBackward1>),\n",
       " tensor(0.1467, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = m(x_train[:1000])\n",
    "stats(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = mse(o, y_train[:1000].squeeze().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0844), tensor(0.7058))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(m[2].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 02b_initializing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "w = torch.randn(512,512)/math.sqrt(512)\n",
    "for i in range(200):    \n",
    "    x = w@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.2225), tensor(35.7302))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.016592334284090612, 32.016327174186706)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std = 0., 0.\n",
    "n=1000\n",
    "for i in range(n):\n",
    "    x = torch.randn(32)\n",
    "    w = torch.randn(100, 32)\n",
    "    y = w@x\n",
    "    mean += y.mean().item()\n",
    "    std += (y**2).mean().item()\n",
    "mean/n, std/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0883), tensor(4.8142))"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(), y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1233,  0.0480,  0.0570, -0.0015,  0.0229, -0.0169, -0.0005,  0.0981,\n",
       "         -0.0112,  0.0689,  0.0260, -0.1014,  0.0292,  0.0116, -0.0076,  0.0644,\n",
       "         -0.0298,  0.0618,  0.0090,  0.0259, -0.0933, -0.0680, -0.0233,  0.0102,\n",
       "         -0.0211, -0.0940, -0.0103,  0.0994,  0.0245,  0.0298, -0.1229, -0.0456,\n",
       "         -0.0930, -0.0409, -0.0207, -0.0325,  0.0518, -0.0786, -0.0440,  0.0068,\n",
       "         -0.0556, -0.0508,  0.1306, -0.0129, -0.0778,  0.1230,  0.0163,  0.1039,\n",
       "          0.0104, -0.0281]),\n",
       " tensor([1.0739, 0.9665, 1.0041, 1.0122, 0.9644, 1.0310, 1.0226, 0.9106, 0.9967,\n",
       "         0.9097, 0.9718, 0.9955, 1.0156, 1.0245, 1.0099, 1.0104, 1.0688, 0.9914,\n",
       "         0.9191, 1.0269, 0.9857, 0.9528, 1.0002, 0.9658, 0.9792, 0.9547, 1.0082,\n",
       "         1.0712, 1.0608, 1.0109, 1.0221, 0.9700, 0.9310, 0.9799, 0.9861, 0.9561,\n",
       "         1.0112, 1.0467, 1.0595, 0.9972, 1.0612, 0.9885, 0.9632, 1.0269, 1.0358,\n",
       "         1.0371, 1.0463, 1.0602, 1.0161, 0.9818]))"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.mean(dim=1), w.std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9861, 0.9482, 0.7974, 0.9973, 1.0806, 0.9296, 1.1403, 0.9300, 1.0402,\n",
       "        1.0443, 0.9706, 0.9451, 1.0016, 1.0114, 0.9424, 1.2161, 0.9011, 0.9269,\n",
       "        1.0766, 1.0051, 0.9971, 0.9165, 1.0086, 0.9589, 0.9908, 0.9972, 1.1428,\n",
       "        0.9858, 0.9135, 0.8405, 1.0912, 1.1305, 0.7531, 1.1185, 1.1186, 0.9244,\n",
       "        0.9840, 1.0119, 0.8395, 1.0265, 0.8017, 1.2087, 1.0237, 0.9954, 1.0181,\n",
       "        0.9400, 1.0371, 0.8747, 0.7978, 1.0548, 1.0232, 0.9359, 1.2695, 0.9617,\n",
       "        1.0008, 0.9207, 0.9276, 1.1736, 0.9094, 0.9807, 1.0287, 0.9980, 1.0306,\n",
       "        0.8410, 0.9552, 1.0514, 0.9007, 0.9864, 0.9331, 0.9430, 0.9479, 0.9631,\n",
       "        0.8606, 1.1455, 1.0436, 1.0259, 1.0779, 1.0314, 0.9683, 1.0342, 1.0324,\n",
       "        0.9930, 0.9335, 0.8747, 1.1453, 1.0166, 0.9305, 0.9945, 0.9811, 1.0576,\n",
       "        0.9134, 0.9097, 0.8807, 0.9981, 1.0646, 0.9226, 0.8245, 1.0424, 1.1546,\n",
       "        1.0204, 1.0111, 1.1093, 1.1674, 0.9387, 1.0724, 1.0099, 0.9880, 1.1482,\n",
       "        0.7920, 0.9116, 1.0070, 1.0148, 1.0982, 0.9267, 0.8814, 1.0747, 1.0812,\n",
       "        1.0292, 1.2721, 0.9459, 1.0702, 1.0343, 0.9912, 1.1520, 0.9212, 0.9466,\n",
       "        1.0271, 1.0699, 1.0693, 1.0962, 0.9495, 0.9594, 1.0863, 1.0389, 1.0045,\n",
       "        1.2101, 0.8665, 1.0163, 0.9517, 0.8819, 0.9323, 0.9782, 1.0076, 1.0232,\n",
       "        0.8882, 0.8711, 0.9453, 1.0065, 1.0212, 0.9623, 1.0220, 1.0838, 0.9445,\n",
       "        0.9489, 0.8762, 0.9275, 0.9130, 1.0410, 0.9586, 0.8153, 1.0481, 0.8439,\n",
       "        1.1787, 0.9346, 1.1269, 1.0013, 0.9575, 1.1830, 0.8330, 1.0596, 1.0850,\n",
       "        1.0073, 0.8752, 1.1686, 1.1137, 0.9115, 1.0970, 1.0461, 1.0061, 1.1073,\n",
       "        1.2447, 1.2442, 1.0062, 1.0956, 0.9050, 1.0829, 1.0540, 0.9603, 1.0098,\n",
       "        1.0533, 0.8974, 1.0364, 1.1008, 0.9727, 0.8763, 1.0383, 0.9519, 1.0568,\n",
       "        0.9078, 1.1428, 1.0451, 0.9786, 0.8376, 0.9874, 0.9906, 1.1093, 0.9174,\n",
       "        0.9952, 0.9507, 0.9698, 0.7917, 1.0730, 0.9926, 1.0154, 1.0565, 0.9688,\n",
       "        0.8928, 1.1055, 0.9823, 0.9749, 1.0797, 1.1795, 0.9457, 0.9222, 0.7480,\n",
       "        0.8954, 1.1320, 0.8787, 0.9617, 0.8700, 0.8947, 1.0310, 1.0130, 0.8402,\n",
       "        1.0739, 0.9022, 0.8737, 1.1636, 1.0179, 0.9552, 1.1502, 0.8764, 1.0885,\n",
       "        0.9923, 0.9330, 0.8580, 1.1705, 0.8085, 0.9542, 1.1392, 0.8967, 0.9905,\n",
       "        1.1291, 0.9360, 1.1124, 1.1125])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " w.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047691911458969116 2.0805296897888184\n",
      "-0.09473999589681625 0.10034643113613129\n",
      "0.30879807472229004 0.3178930878639221\n",
      "-0.00023695515119470656 1.6705532743799267e-06\n",
      "0.2800590991973877 0.6824519038200378\n",
      "0.4337385296821594 0.8597820997238159\n",
      "-0.10465200245380402 0.18564598262310028\n",
      "0.00699568260461092 0.00838479120284319\n",
      "0.42169514298439026 2.1988871097564697\n",
      "-0.3262069821357727 0.4019150137901306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09731425050122197, 0.6835837780258543)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std = 0., 0.\n",
    "n=10\n",
    "for i in range(n):\n",
    "    x = torch.randn(1)\n",
    "    w = torch.randn(10,1)\n",
    "    y = w@x\n",
    "    mean += y.mean().item()\n",
    "    std += (y**2).mean().item()\n",
    "#     print(x, w, y, y.mean().item(), (y**2).mean().item())\n",
    "    print(y.mean().item(), (y**2).mean().item())\n",
    "mean/n, std/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03_minibatch_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_02 import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "n, nc = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(ni, nh), nn.ReLU(), nn.Linear(nh, no)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for i in self.layers:\n",
    "            x = i(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model(nc, nh, c.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_train = m(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Loss function - log_softmax, NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train.exp().sum(dim=1).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def log_softmax(x): \n",
    "    return (x.exp()/x.exp().sum(dim=-1).unsqueeze(1)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pt_ls = log_softmax(pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_near(F.log_softmax(pred_train, dim=-1), pt_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def NLL_loss(pred, tar):\n",
    "    #     -tar*pred\n",
    "    return -pred[np.arange(pred.shape[0]), tar].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = NLL_loss(pt_ls, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3048, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3048, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss()(pt_ls, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# can use logsumexp trick to compute denominator without any overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3048, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(F.log_softmax(pred_train,dim=-1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "x_train.shape\n",
    "bs = 64\n",
    "lr = 0.5\n",
    "epochs= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Basic loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    idx=0\n",
    "    for i in range(math.ceil(x_train.shape[0]/bs)):\n",
    "        xb = x_train[idx:idx+bs, :]\n",
    "        yb = y_train[idx:idx+bs]\n",
    "        idx += bs\n",
    "        pred_ls = m(xb)\n",
    "        loss = loss_func(pred_ls, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for l in m.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= lr*l.weight.grad\n",
    "                    l.bias -= lr*l.bias.grad\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    #         m.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9858)"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(m(x_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class model1(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return self.l2(self.relu(self.l1(x)))\n",
    "#         return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m1 = model1(784, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model1(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('l1', Linear(in_features=784, out_features=50, bias=True)), ('l2', Linear(in_features=50, out_features=10, bias=True)), ('relu', ReLU())] ...\n",
      "[('', model1(\n",
      "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")), ('l1', Linear(in_features=784, out_features=50, bias=True)), ('l2', Linear(in_features=50, out_features=10, bias=True)), ('relu', ReLU())]\n"
     ]
    }
   ],
   "source": [
    "print(list(m1.named_children()), '...')\n",
    "print(list(m1.named_modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m2 = model1(784, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model1(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('l1', Linear(in_features=784, out_features=50, bias=True)), ('l2', Linear(in_features=50, out_features=10, bias=True))] ...\n",
      "[('', model1(\n",
      "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")), ('l1', Linear(in_features=784, out_features=50, bias=True)), ('l2', Linear(in_features=50, out_features=10, bias=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(m2.named_children()), '...')\n",
    "print(list(m2.named_modules()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Testing __setattr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class test():\n",
    "    def __init__(self, x1, x2):\n",
    "        self.x1, self.x2 = x1, x2\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        print(f'seattr invoked : {k} : {v}')\n",
    "        super().__setattr__(k,v)\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seattr invoked : x1 : one\n",
      "seattr invoked : x2 : two\n"
     ]
    }
   ],
   "source": [
    "t = test('one', 'two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one'"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class dummymodel():\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k]=v\n",
    "        super().__setattr__(k, v)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return (f'{self._modules}')\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return self.l2(F.relu(self.l1(x)))\n",
    "    \n",
    "    def named_parameters(self):\n",
    "        for k, l in zip(self._modules.keys(), self._modules.values()):\n",
    "            for p in l.parameters():\n",
    "                yield k, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dm = dummymodel(3, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=3, out_features=4, bias=True), 'l2': Linear(in_features=4, out_features=2, bias=True)}"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('l1', Parameter containing:\n",
       "  tensor([[ 0.2127, -0.2791, -0.0977],\n",
       "          [ 0.2645, -0.4434, -0.1080],\n",
       "          [-0.5036,  0.5682, -0.5582],\n",
       "          [ 0.0379, -0.4723,  0.0550]], requires_grad=True)),\n",
       " ('l1', Parameter containing:\n",
       "  tensor([-0.4856, -0.4348, -0.1240,  0.2457], requires_grad=True)),\n",
       " ('l2', Parameter containing:\n",
       "  tensor([[-0.3092,  0.2318,  0.0410, -0.2967],\n",
       "          [ 0.3150, -0.3290, -0.4729,  0.0037]], requires_grad=True)),\n",
       " ('l2', Parameter containing:\n",
       "  tensor([0.2672, 0.0959], requires_grad=True))]"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dm.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('', Model())], [], [])"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.named_modules()), list(m.named_children()), list(m.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ni, nh, no):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(ni, nh), nn.ReLU(), nn.Linear(nh, no)]\n",
    "        for c, i in enumerate(self.layers): self.add_module(f'layer_{c}', i)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for i in self.layers:\n",
    "            x = i(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m3 = Model(784, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('', Model(\n",
       "     (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "     (layer_1): ReLU()\n",
       "     (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       "   )),\n",
       "  ('layer_0', Linear(in_features=784, out_features=50, bias=True)),\n",
       "  ('layer_1', ReLU()),\n",
       "  ('layer_2', Linear(in_features=50, out_features=10, bias=True))],\n",
       " [('layer_0', Linear(in_features=784, out_features=50, bias=True)),\n",
       "  ('layer_1', ReLU()),\n",
       "  ('layer_2', Linear(in_features=50, out_features=10, bias=True))])"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m3.named_modules()), list(m3.named_children())#, list(m3.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Using optim to refactor step and grad - Here we refactored params as well but params shud be done as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class optimizer():\n",
    "    def __init__(self, lr, model):\n",
    "        self.lr = lr\n",
    "        self.model = model\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for l in self.model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= self.lr*l.weight.grad\n",
    "                    l.bias -= self.lr*l.bias.grad\n",
    "    def zero_grad(self):\n",
    "        with torch.no_grad():\n",
    "            for l in self.model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cop = optimizer(0.5, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for e in range(epochs+5):\n",
    "    idx=0\n",
    "    for i in range(math.ceil(x_train.shape[0]/bs)):\n",
    "        xb = x_train[idx:idx+bs, :]\n",
    "        yb = y_train[idx:idx+bs]\n",
    "        idx += bs\n",
    "        pred_ls = m(xb)\n",
    "        loss = loss_func(pred_ls, yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        cop.step()\n",
    "        cop.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9737)"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(m(x_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Exploring torch nn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m=models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = nn.Sequential(nn.Conv2d(2,3,3),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(3,4,3),\n",
    "                  nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.named_children())[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1',\n",
       "  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)),\n",
       " ('bn1',\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('relu', ReLU(inplace)),\n",
       " ('maxpool',\n",
       "  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n",
       " ('layer1', Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer1.0', BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )),\n",
       " ('layer1.0.conv1',\n",
       "  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer1.0.bn1',\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer1.0.relu', ReLU(inplace)),\n",
       " ('layer1.0.conv2',\n",
       "  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer1.0.bn2',\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer1.1', BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )),\n",
       " ('layer1.1.conv1',\n",
       "  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer1.1.bn1',\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer1.1.relu', ReLU(inplace)),\n",
       " ('layer1.1.conv2',\n",
       "  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer1.1.bn2',\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer2', Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer2.0', BasicBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer2.0.conv1',\n",
       "  Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       " ('layer2.0.bn1',\n",
       "  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer2.0.relu', ReLU(inplace)),\n",
       " ('layer2.0.conv2',\n",
       "  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer2.0.bn2',\n",
       "  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer2.0.downsample', Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )),\n",
       " ('layer2.0.downsample.0',\n",
       "  Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n",
       " ('layer2.0.downsample.1',\n",
       "  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer2.1', BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )),\n",
       " ('layer2.1.conv1',\n",
       "  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer2.1.bn1',\n",
       "  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer2.1.relu', ReLU(inplace)),\n",
       " ('layer2.1.conv2',\n",
       "  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer2.1.bn2',\n",
       "  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer3', Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer3.0', BasicBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer3.0.conv1',\n",
       "  Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       " ('layer3.0.bn1',\n",
       "  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer3.0.relu', ReLU(inplace)),\n",
       " ('layer3.0.conv2',\n",
       "  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer3.0.bn2',\n",
       "  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer3.0.downsample', Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )),\n",
       " ('layer3.0.downsample.0',\n",
       "  Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n",
       " ('layer3.0.downsample.1',\n",
       "  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer3.1', BasicBlock(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )),\n",
       " ('layer3.1.conv1',\n",
       "  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer3.1.bn1',\n",
       "  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer3.1.relu', ReLU(inplace)),\n",
       " ('layer3.1.conv2',\n",
       "  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer3.1.bn2',\n",
       "  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer4', Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer4.0', BasicBlock(\n",
       "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )),\n",
       " ('layer4.0.conv1',\n",
       "  Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n",
       " ('layer4.0.bn1',\n",
       "  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer4.0.relu', ReLU(inplace)),\n",
       " ('layer4.0.conv2',\n",
       "  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer4.0.bn2',\n",
       "  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer4.0.downsample', Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )),\n",
       " ('layer4.0.downsample.0',\n",
       "  Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n",
       " ('layer4.0.downsample.1',\n",
       "  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer4.1', BasicBlock(\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )),\n",
       " ('layer4.1.conv1',\n",
       "  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer4.1.bn1',\n",
       "  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('layer4.1.relu', ReLU(inplace)),\n",
       " ('layer4.1.conv2',\n",
       "  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n",
       " ('layer4.1.bn2',\n",
       "  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       " ('avgpool', AdaptiveAvgPool2d(output_size=(1, 1))),\n",
       " ('fc', Linear(in_features=512, out_features=1000, bias=True))]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.named_modules())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    }
   ],
   "source": [
    "for i,j in m.named_children():\n",
    "    if isinstance(j, nn.BatchNorm2d):\n",
    "        print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in list(list(m.named_children())[0][1].named_children()):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def layer_match(m, match):\n",
    "    for i,j in m.named_children():\n",
    "        print(i, j)\n",
    "        if isinstance(j, match):\n",
    "            print(i, j)\n",
    "        layer_match(j, match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "conv1 Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu ReLU(inplace)\n",
      "maxpool MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "layer1 Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "0 BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "conv1 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv1 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu ReLU(inplace)\n",
      "conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "1 BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "conv1 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv1 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu ReLU(inplace)\n",
      "conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2 Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "0 BasicBlock(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "conv1 Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "conv1 Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu ReLU(inplace)\n",
      "conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "downsample Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "0 Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "0 Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "1 BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "conv1 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv1 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu ReLU(inplace)\n",
      "conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3 Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "0 BasicBlock(\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "conv1 Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "conv1 Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu ReLU(inplace)\n",
      "conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "downsample Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "0 Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "0 Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "1 BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "conv1 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv1 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu ReLU(inplace)\n",
      "conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4 Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "0 BasicBlock(\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "conv1 Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "conv1 Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu ReLU(inplace)\n",
      "conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "downsample Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "0 Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "0 Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "1 BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "conv1 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv1 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu ReLU(inplace)\n",
      "conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "avgpool AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "fc Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "layer_match(models.resnet18(), nn.Conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DataLoader and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor(5))"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape, train_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "class Dataloader():\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds, bs=32)\n",
    "valid_dl = Dataloader(valid_ds, bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3, 3, 0, 7, 4, 9, 8,\n",
       "         0, 9, 4, 1, 4, 4, 6, 0]))"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler\n",
    "class samp():\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(len(self.ds))\n",
    "        print(self.idxs)\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing indexing \n",
    "n=14\n",
    "train_ds = Dataset(x_train[:n], y_train[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 784])"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:100][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8305  ,  1.238106,  0.883706,  1.364315],\n",
       "       [ 0.973216,  1.233665, -0.009622, -0.318184],\n",
       "       [ 0.46026 ,  0.027519,  0.051482,  0.311302]])"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.random.randn(3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8305  ,  1.238106,  0.883706,  1.364315],\n",
       "       [ 0.973216,  1.233665, -0.009622, -0.318184],\n",
       "       [ 0.46026 ,  0.027519,  0.051482,  0.311302]])"
      ]
     },
     "execution_count": 1062,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = samp(train_ds, 5)\n",
    "t1 = iter(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12,  5,  2,  6,  9,  8,  4,  7,  3,  1, 13,  0, 11, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([12,  5,  2,  6,  9])"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 4, 7, 3, 1])"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13,  0, 11, 10])"
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1047-8d9276fec067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler\n",
    "class samp():\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(len(self.ds))\n",
    "#         print(self.idxs)\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs),torch.stack(ys)\n",
    "\n",
    "class Dataloader():\n",
    "    def __init__(self, ds, bs, sampler, collate_fn=collate):\n",
    "        self.ds, self.bs = ds, bs\n",
    "        self.collate_fn = collate_fn\n",
    "    def __iter__(self):\n",
    "        samp = self.sampler(self.ds, self.bs)\n",
    "        for i in samp: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "train_ds = Dataset(x_train[:n], y_train[:n])\n",
    "dl = Dataloader(train_ds, 16, samp)\n",
    "tl = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataloader' object has no attribute 'sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1100-5cbcd081033a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1098-542db726bbb6>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataloader' object has no attribute 'sampler'"
     ]
    }
   ],
   "source": [
    "next(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1091-5cbcd081033a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 1, 4, 1, 3, 1, 2, 0, 5, 4]))"
      ]
     },
     "execution_count": 1092,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = iter(dl)\n",
    "next(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fav3p2",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
