{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks as GUI events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(o): print('hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [ipywidget docs](https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20Events.html):\n",
    "\n",
    "- *the button widget is used to handle mouse clicks. The on_click method of the Button can be used to register function to be called when the button is clicked*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = widgets.Button(description='Click me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.on_click(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NB: When callbacks are used in this way they are often called \"events\".*\n",
    "\n",
    "Did you know what you can create interactive apps in Jupyter with these widgets? Here's an example from [plotly](https://plot.ly/python/widget-app/):\n",
    "\n",
    "![](https://cloud.githubusercontent.com/assets/12302455/16637308/4e476280-43ac-11e6-9fd3-ada2c9506ee1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your own callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_calculation():\n",
    "    res = 0\n",
    "    for i in range(5):\n",
    "        res += i*i\n",
    "        sleep(1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_calculation(cb=None):\n",
    "    res = 0\n",
    "    for i in range(5):\n",
    "        res += i*i\n",
    "        sleep(1)\n",
    "        if cb: cb(i)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(epoch):\n",
    "    print(f\"Awesome! We've finished epoch {epoch}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(show_progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambdas and partials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(lambda o: print(f\"Awesome! We've finished epoch {o}!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(exclamation, epoch):\n",
    "    print(f\"{exclamation}! We've finished epoch {epoch}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(lambda o: show_progress(\"OK I guess\", o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_show_progress(exclamation):\n",
    "    _inner = lambda epoch: print(f\"{exclamation}! We've finished epoch {epoch}!\")\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(make_show_progress(\"Nice!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_show_progress(exclamation):\n",
    "    # Leading \"_\" is generally understood to be \"private\"\n",
    "    def _inner(epoch): print(f\"{exclamation}! We've finished epoch {epoch}!\")\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(make_show_progress(\"Nice!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = make_show_progress(\"Terrific\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(make_show_progress(\"Amazing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(partial(show_progress, \"OK I guess\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = partial(show_progress, \"OK I guess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks as callable classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressShowingCallback():\n",
    "    def __init__(self, exclamation=\"Awesome\"): self.exclamation = exclamation\n",
    "    def __call__(self, epoch): print(f\"{self.exclamation}! We've finished epoch {epoch}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = ProgressShowingCallback(\"Just super\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple callback funcs; `*args` and `**kwargs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(*args, **kwargs): print(f\"args: {args}; kwargs: {kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(3, 'a', thing1=\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: We've been guilty of over-using kwargs in fastai - it's very convenient for the developer, but is annoying for the end-user unless care is taken to ensure docs show all kwargs too. kwargs can also hide bugs (because it might not tell you about a typo in a param name). In [R](https://www.r-project.org/) there's a very similar issue (R uses `...` for the same thing), and matplotlib uses kwargs a lot too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_calculation(cb=None):\n",
    "    res = 0\n",
    "    for i in range(5):\n",
    "        if cb: cb.before_calc(i)\n",
    "        res += i*i\n",
    "        sleep(1)\n",
    "        if cb: cb.after_calc(i, val=res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintStepCallback():\n",
    "    def __init__(self): pass\n",
    "    def before_calc(self, *args, **kwargs): print(f\"About to start\")\n",
    "    def after_calc (self, *args, **kwargs): print(f\"Done step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(PrintStepCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintStatusCallback():\n",
    "    def __init__(self): pass\n",
    "    def before_calc(self, epoch, **kwargs): print(f\"About to start: {epoch}\")\n",
    "    def after_calc (self, epoch, val, **kwargs): print(f\"After {epoch}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(PrintStatusCallback())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_calculation(cb=None):\n",
    "    res = 0\n",
    "    for i in range(5):\n",
    "        if cb and hasattr(cb,'before_calc'): cb.before_calc(i)\n",
    "        res += i*i\n",
    "        sleep(1)\n",
    "        if cb and hasattr(cb,'after_calc'):\n",
    "            if cb.after_calc(i, res):\n",
    "                print(\"stopping early\")\n",
    "                break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintAfterCallback():\n",
    "    def after_calc (self, epoch, val):\n",
    "        print(f\"After {epoch}: {val}\")\n",
    "        if val>10: return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_calculation(PrintAfterCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowCalculator():\n",
    "    def __init__(self, cb=None): self.cb,self.res = cb,0\n",
    "    \n",
    "    def callback(self, cb_name, *args):\n",
    "        if not self.cb: return\n",
    "        cb = getattr(self.cb,cb_name, None)\n",
    "        if cb: return cb(self, *args)\n",
    "\n",
    "    def calc(self):\n",
    "        for i in range(5):\n",
    "            self.callback('before_calc', i)\n",
    "            self.res += i*i\n",
    "            sleep(1)\n",
    "            if self.callback('after_calc', i):\n",
    "                print(\"stopping early\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifyingCallback():\n",
    "    def after_calc (self, calc, epoch):\n",
    "        print(f\"After {epoch}: {calc.res}\")\n",
    "        if calc.res>10: return True\n",
    "        if calc.res<3: calc.res = calc.res*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = SlowCalculator(ModifyingCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator.calc()\n",
    "calculator.res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `__dunder__` thingies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anything that looks like `__this__` is, in some way, *special*. Python, or some library, can define some functions that they will call at certain documented times. For instance, when your class is setting up a new object, python will call `__init__`. These are defined as part of the python [data model](https://docs.python.org/3/reference/datamodel.html#object.__init__).\n",
    "\n",
    "For instance, if python sees `+`, then it will call the special method `__add__`. If you try to display an object in Jupyter (or lots of other places in Python) it will call `__repr__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SloppyAdder():\n",
    "    def __init__(self,o): self.o=o\n",
    "    def __add__(self,b): return SloppyAdder(self.o + b.o + 0.01)\n",
    "    def __repr__(self): return str(self.o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SloppyAdder(1)\n",
    "b = SloppyAdder(2)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special methods you should probably know about (see data model link above) are:\n",
    "\n",
    "- `__getitem__`\n",
    "- `__getattr__`\n",
    "- `__setattr__`\n",
    "- `__del__`\n",
    "- `__init__`\n",
    "- `__new__`\n",
    "- `__enter__`\n",
    "- `__exit__`\n",
    "- `__len__`\n",
    "- `__repr__`\n",
    "- `__str__`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance is the average of how far away each data point is from the mean. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1.,2.,4.,18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = t.mean(); m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t-m).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops. We can't do that. Because by definition the positives and negatives cancel out. So we can fix that in one of (at least) two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t-m).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t-m).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the first of these is now a totally different scale, since we squared. So let's undo that at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t-m).pow(2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're still different. Why?\n",
    "\n",
    "Note that we have one outlier (`18`). In the version where we square everything, it makes that much bigger than everything else.\n",
    "\n",
    "`(t-m).pow(2).mean()` is referred to as **variance**. It's a measure of how spread out the data is, and is particularly sensitive to outliers.\n",
    "\n",
    "When we take the sqrt of the variance, we get the **standard deviation**. Since it's on the same kind of scale as the original data, it's generally more interpretable. However, since `sqrt(1)==1`, it doesn't much matter which we use when talking about *unit variance* for initializing neural nets.\n",
    "\n",
    "`(t-m).abs().mean()` is referred to as the **mean absolute deviation**. It isn't used nearly as much as it deserves to be, because mathematicians don't like how awkward it is to work with. But that shouldn't stop us, because we have computers and stuff.\n",
    "\n",
    "Here's a useful thing to note about variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t-m).pow(2).mean(), (t*t).mean() - (m*m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see why these are equal if you want to work thru the algebra. Or not.\n",
    "\n",
    "But, what's important here is that the latter is generally much easier to work with. In particular, you only have to track two things: the sum of the data, and the sum of squares of the data. Whereas in the first form you actually have to go thru all the data twice (once to calculate the mean, once to calculate the differences).\n",
    "\n",
    "Let's go steal the LaTeX from [Wikipedia](https://en.wikipedia.org/wiki/Variance):\n",
    "\n",
    "$$\\operatorname{E}\\left[X^2 \\right] - \\operatorname{E}[X]^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance and correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how Wikipedia defines covariance:\n",
    "\n",
    "$$\\operatorname{cov}(X,Y) = \\operatorname{E}{\\big[(X - \\operatorname{E}[X])(Y - \\operatorname{E}[Y])\\big]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see that in code. So now we need two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `u` is twice `t`, plus a bit of randomness\n",
    "u = t*2\n",
    "u *= torch.randn_like(t)/10+0.95\n",
    "\n",
    "plt.scatter(t, u);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = (t-t.mean())*(u-u.mean()); prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.randn_like(t)\n",
    "plt.scatter(t, v);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((t-t.mean())*(v-v.mean())).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's generally more conveniently defined like so:\n",
    "\n",
    "$$\\operatorname{E}\\left[X Y\\right] - \\operatorname{E}\\left[X\\right] \\operatorname{E}\\left[Y\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = (t*v).mean() - t.mean()*v.mean(); cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, you're not allowed to look at an equation (or especially type it in LaTeX) without also typing it in Python and actually calculating some values. Ideally, you should also plot some values.\n",
    "\n",
    "Finally, here is the Pearson correlation coefficient:\n",
    "\n",
    "$$\\rho_{X,Y}= \\frac{\\operatorname{cov}(X,Y)}{\\sigma_X \\sigma_Y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov / (t.std() * v.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's just a scaled version of the same thing. Question: *Why is it scaled by standard deviation, and not by variance or mean or something else?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our final `logsoftmax` definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is:\n",
    "\n",
    "$$\\hbox{logsoftmax(x)}_{i} = x_{i} - \\log \\sum_{j} e^{x_{j}}$$ \n",
    "\n",
    "And our cross entropy loss is:\n",
    "$$-\\log(p_{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browsing source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jump to tag/symbol by with (with completions)\n",
    "- Jump to current tag\n",
    "- Jump to library tags\n",
    "- Go back\n",
    "- Search\n",
    "- Outlining / folding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
